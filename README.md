
<p align="center">
  <img src="./imgs/trustai.png" align="middle"  width="500" />
</p>


<p align="center">
<a href="https://pypi.org/project/trustai/"><img src="https://img.shields.io/pypi/v/trustai.svg?&color=green"></a>
<a href="./LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
<a href=""><img src="https://img.shields.io/badge/python-3.6.2+-orange.svg"></a>
<a href=""><img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-red.svg"></a>
</p>

<h4 align="center">
  <a href=#å®‰è£…> å®‰è£… </a> |
  <a href=#å¿«é€Ÿå¼€å§‹> å¿«é€Ÿå¼€å§‹ </a>|
  <a href=#å¯ä¿¡åˆ†æåŠŸèƒ½> å¯ä¿¡åˆ†æåŠŸèƒ½ </a> |
  <a href=#å¯ä¿¡å¢å¼ºåŠŸèƒ½> å¯ä¿¡å¢å¼ºåŠŸèƒ½ </a> |
  <a href=#åº”ç”¨æ¡ˆä¾‹> åº”ç”¨æ¡ˆä¾‹ </a> |
  <a href=#è¯„æµ‹æ¦œå•> è¯„æµ‹æ¦œå• </a> |
  <a href=#å­¦æœ¯æ–‡çŒ®> å­¦æœ¯æ–‡çŒ® </a>
</h4>

**TrustAI**æ˜¯åŸºäºæ·±åº¦å­¦ä¹ å¹³å°ã€é£æ¡¨ã€([PaddlePaddle](https://github.com/PaddlePaddle/Paddle))å¼€å‘çš„é›†å¯ä¿¡åˆ†æå’Œå¢å¼ºäºä¸€ä½“çš„å¯ä¿¡AIå·¥å…·é›†ï¼ŒåŠ©åŠ›NLPå¼€å‘è€…æå‡æ·±åº¦å­¦ä¹ æ¨¡å‹æ•ˆæœå’Œå¯ä¿¡åº¦ï¼Œæ¨åŠ¨æ¨¡å‹å®‰å…¨ã€å¯é çš„è½åœ°äºåº”ç”¨ã€‚


## News ğŸ“¢
* ğŸ”¥ 2022.10.30 [å¯è§£é‡Šè¯„æµ‹æ•°æ®é›†](https://www.luge.ai/#/luge/task/taskDetail?taskId=15)å…¥é©»åƒè¨€ï¼Œéƒ¨åˆ†æ•°æ®æä¾›äººå·¥æ ‡æ³¨è¯æ®ï¼Œæ¬¢è¿å¤§å®¶ä½¿ç”¨ã€‚
* ğŸ”¥ 2022.8.29 [PaddleNLPåˆ†ç±»ç³»ç»Ÿ](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/text_classification)å·²ç»æ¥å…¥TrustAIèƒ½åŠ›ï¼Œæ¬¢è¿å¤§å®¶è¯•ç”¨ã€‚
* ğŸ”¥ 2022.8.20 TrustAI[å‘å¸ƒ](https://mp.weixin.qq.com/s/Ph3uzbUEUj1K7UALdM6OCA)å¯ä¿¡å¢å¼ºèƒ½åŠ›åŠåº”ç”¨æ¡ˆä¾‹ã€‚
* ğŸ‰ 2022.5.20 TrustAIé¦–æ¬¡[å‘å¸ƒ](https://mp.weixin.qq.com/s/AqYReKRnki9TwI5huY1f5Q)ï¼

## <p id="å¯ä¿¡åˆ†æåŠŸèƒ½">ğŸ‘å¯ä¿¡åˆ†æåŠŸèƒ½</p>
TrustAIæä¾›ç‰¹å¾çº§è¯æ®å’Œå®ä¾‹çº§è¯æ®åˆ†ææ–¹æ³•ï¼Œå…¨æ–¹ä½è§£é‡Šæ¨¡å‹çš„é¢„æµ‹ï¼Œå¸®åŠ©å¼€å‘è€…äº†è§£æ¨¡å‹é¢„æµ‹æœºåˆ¶ï¼Œä»¥åŠååŠ©ä½¿ç”¨è€…åŸºäºè¯æ®åšå‡ºæ­£ç¡®å†³ç­–ã€‚

### ç‰¹å¾çº§è¯æ®åˆ†æ

æ ¹æ®æ¨¡å‹é¢„æµ‹ç»“æœï¼Œä»è¾“å…¥æ–‡æœ¬ä¸­æå–æ¨¡å‹é¢„æµ‹æ‰€ä¾èµ–çš„è¯æ®ï¼Œå³è¾“å…¥æ–‡æœ¬ä¸­æ”¯æŒæ¨¡å‹é¢„æµ‹çš„è‹¥å¹²é‡è¦è¯ã€‚

<p align="center">
  <img src="./imgs/token.png" align="middle", width="500" />
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [åŸºäºTrustAIçš„ç‰¹å¾çº§è¯æ®åˆ†æç¤ºä¾‹-ä¸­æ–‡æƒ…æ„Ÿåˆ†æä»»åŠ¡](https://aistudio.baidu.com/aistudio/projectdetail/4431334)

å…³äºæ–¹æ³•æ›´å¤šè¯¦ç»†å†…å®¹å¯å‚è€ƒ - [ç‰¹å¾çº§è¯æ®åˆ†ææ–‡æ¡£](./trustai/interpretation/token_level/README.md)

### å®ä¾‹çº§è¯æ®åˆ†æ


ä»è®­ç»ƒæ•°æ®ä¸­æ‰¾å‡ºå¯¹å½“å‰é¢„æµ‹æ–‡æœ¬å½±å“è¾ƒå¤§çš„è‹¥å¹²è®­ç»ƒæ ·æœ¬ä½œä¸ºæ¨¡å‹é¢„æµ‹ä¾èµ–è¯æ®ã€‚
<p align="center">
  <img src="./imgs/example.png" align="middle", width="500" />
</p>



åº”ç”¨ç¤ºä¾‹è§AI Studio - [åŸºäºTrustAIçš„å®ä¾‹çº§è¯æ®åˆ†æç¤ºä¾‹-ä¸­æ–‡æƒ…æ„Ÿåˆ†æä»»åŠ¡](https://aistudio.baidu.com/aistudio/projectdetail/4433286)

å…³äºæ–¹æ³•æ›´å¤šè¯¦ç»†å†…å®¹å¯å‚è€ƒ - [å®ä¾‹çº§è¯æ®åˆ†ææ–‡æ¡£](./trustai/interpretation/example_level/README.md)

## <p id="å¯ä¿¡å¢å¼ºåŠŸèƒ½">ğŸ’¥å¯ä¿¡å¢å¼ºåŠŸèƒ½</p>

åŸºäºå¯¹æ¨¡å‹é¢„æµ‹ä¾èµ–è¯æ®çš„åˆ†æï¼ŒTrustAIæä¾›äº†æ¨¡å‹ç¼ºé™·è¯†åˆ«å’Œå¯¹åº”çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œå³å¯ä¿¡å¢å¼ºåŠŸèƒ½ã€‚å½“å‰ï¼Œä»è®­ç»ƒæ•°æ®å’Œè®­ç»ƒæœºåˆ¶ä¼˜åŒ–è§’åº¦ï¼ŒTrustAIå¼€æºäº†é’ˆå¯¹3ç§æ•°æ®ç¼ºé™·çš„è¯†åˆ«æ–¹æ¡ˆå’Œä¼˜åŒ–æ–¹æ¡ˆï¼Œå¸Œæœ›èƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ä»¥æœ€å°æˆæœ¬è§£å†³è®­ç»ƒæ•°æ®ç¼ºé™·é—®é¢˜ã€‚åŒæ—¶ï¼ŒTrustAIå¼€æºäº†ä¸€ç§åŸºäºè¯æ®æŒ‡å¯¼çš„é¢„æµ‹æœºåˆ¶ä¼˜åŒ–æ–¹æ¡ˆï¼Œç”¨æ¥è§£å†³é•¿æ–‡æœ¬ç†è§£é—®é¢˜ã€‚

### è®­ç»ƒæ•°æ®ä¸­è„æ•°æ®è‡ªåŠ¨è¯†åˆ«


TrustAIæä¾›äº†è„æ•°æ®ï¼ˆå³æ ‡æ³¨è´¨é‡å·®çš„æ•°æ®ï¼‰è‡ªåŠ¨è¯†åˆ«åŠŸèƒ½ï¼Œå¸®åŠ©é™ä½äººå·¥æ£€æŸ¥æ•°æ®çš„æˆæœ¬ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šï¼ŒTrustAIè‡ªåŠ¨è¯†åˆ«çš„è„æ•°æ®æ¯”ä¾‹è¿œé«˜äºéšæœºé€‰æ‹©ç­–ç•¥ã€‚

<p align="center">
<img align="center" src="./imgs/dirty_analysis.png", width=400><br>
å›¾1 ä¸åŒç­–ç•¥çš„è„æ•°æ®è¯†åˆ«æ•ˆæœ
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [è®­ç»ƒæ•°æ®ä¸­è„æ•°æ®è‡ªåŠ¨è¯†åˆ«ç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4434058)

### è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³è¯†åˆ«åŠæœ‰æ•ˆæ•°æ®å¢å¼º

è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³ä¼šå¯¼è‡´æ¨¡å‹åœ¨å¯¹åº”çš„æµ‹è¯•æ•°æ®ä¸Šè¡¨ç°ä¸å¥½ã€‚åŸºäºå®ä¾‹çº§è¯æ®åˆ†ææ–¹æ³•ï¼ŒTrustAIå¯è¯†åˆ«è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³çš„æµ‹è¯•æ•°æ®ï¼ˆè¿™äº›æ•°æ®æ„æˆçš„é›†åˆç§°ä¸ºç›®æ ‡é›†ï¼‰ï¼Œæ¨¡å‹åœ¨ç›®æ ‡é›†ä¸Šæ•ˆæœé™ä½20%å·¦å³ã€‚è¿›ä¸€æ­¥åœ°ï¼Œä¸ºé™ä½æ ‡æ³¨æˆæœ¬ï¼ŒTrustAIæä¾›æœ‰æ•ˆæ•°æ®é€‰æ‹©ç­–ç•¥ï¼Œå³ä»æœªæ ‡æ³¨æ•°æ®ä¸­é€‰æ‹©å¯ä»¥æé«˜è®­ç»ƒæ•°æ®è¦†ç›–åº¦å’Œæ¨¡å‹æ•ˆæœçš„æ•°æ®è¿›è¡Œæ ‡æ³¨ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šï¼ŒTrustAIæä¾›çš„æœ‰æ•ˆæ•°æ®å¢å¼ºç­–ç•¥å¯¹æ¨¡å‹åœ¨ç›®æ ‡æ•°æ®ä¸Šçš„æ•ˆæœæå‡è¿œé«˜äºéšæœºé€‰æ‹©ç­–ç•¥ã€‚

<p align="center">
<img align="center" src="./imgs/sparse_analysis.png", width=400><br>
å›¾2 ç›®æ ‡é›†æå‡çš„æ•ˆæœ
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³è¯†åˆ«åŠæœ‰æ•ˆæ•°æ®å¢å¼ºç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4434403)


### è®­ç»ƒæ•°æ®åˆ†å¸ƒåç½®è¯†åˆ«åŠåç½®ç¼“è§£
ç¥ç»ç½‘ç»œæ¨¡å‹ä¼šåˆ©ç”¨æ•°æ®é›†ä¸­çš„åç½®åšé¢„æµ‹ï¼Œè¿™ä¼šå¯¼è‡´æ¨¡å‹æ²¡æœ‰å­¦ä¼šç†è§£è¯­è¨€ï¼Œé²æ£’æ€§å·®ã€‚TrustAIæä¾›äº†åˆ†å¸ƒä¿®æ­£å’Œæƒé‡ä¿®æ­£ä¸¤ç§ç­–ç•¥ï¼Œåœ¨ä¸éœ€è¦äººå·¥ä»‹å…¥çš„æ¡ä»¶ä¸‹ï¼Œæœ‰æ•ˆç¼“è§£æ•°æ®åç½®å¯¹æ¨¡å‹è®­ç»ƒçš„å½±å“ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€çš„é²æ£’æ€§æ•°æ®é›†ä¸Šï¼ŒTrustAIçš„æƒé‡ä¿®æ­£å’Œåˆ†å¸ƒä¿®æ­£ç­–ç•¥åˆ†åˆ«å–å¾—æ˜æ˜¾æå‡ã€‚

<p align="center">
<img align="center" src="./imgs/bias_correction.png", width=400><br>
å›¾3 åç½®ä¿®æ­£åæ¨¡å‹åœ¨é²æ£’æ€§æ•°æ®é›†ä¸Šçš„æ•ˆæœ
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [æ•°æ®åˆ†å¸ƒåç½®ç¼“è§£ç­–ç•¥-æ•°æ®æƒé‡ä¿®æ­£ç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4434616)å’Œ[æ•°æ®åˆ†å¸ƒåç½®ç¼“è§£ç­–ç•¥-æ•°æ®åˆ†å¸ƒä¿®æ­£ç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4434652)

### è¯æ®è¯†åˆ«åŠåŸºäºè¯æ®çš„é¢„æµ‹ - é¢„æµ‹æœºåˆ¶ä¼˜åŒ–
åœ¨é•¿æœ¬æ–‡ç†è§£ä»»åŠ¡ä¸­ï¼Œè¾“å…¥ä¸­çš„å†—ä½™ä¿¡æ¯å¾€å¾€ä¼šå¹²æ‰°æ¨¡å‹é¢„æµ‹ï¼Œå¯¼è‡´æ¨¡å‹é²æ£’æ€§å·®ã€‚TrustAIæä¾›äº†â€œè¯æ®è¯†åˆ«-åŸºäºè¯æ®çš„é¢„æµ‹â€ä¸¤é˜¶æ®µé¢„æµ‹æ–¹æ¡ˆï¼Œæ˜¾è‘—æå‡é•¿æ–‡æœ¬ä»»åŠ¡ä¸Šçš„æ¨¡å‹æ•ˆæœï¼Œå°¤å…¶æ˜¯æ¨¡å‹çš„é²æ£’æ€§ã€‚

ä»¥DuReader-robustæ•°æ®é›†çš„è®­ç»ƒæ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œåœ¨DuReader-robustéªŒè¯é›†ã€æµ‹è¯•é›†ä»¥åŠDuReader-checklistæµ‹è¯•é›†ä¸Šè¿›è¡Œäº†æ•ˆæœéªŒè¯ï¼Œåˆ†åˆ«éªŒè¯æ¨¡å‹çš„åŸºæœ¬æ•ˆæœã€é²æ£’æ€§æ•ˆæœã€é¢†åŸŸæ³›åŒ–æ•ˆæœï¼Œå„æ•°æ®é›†ä¸Šçš„ç­”æ¡ˆç²¾å‡†åŒ¹é…ç‡å‡å–å¾—æ˜¾è‘—æå‡ã€‚

<p align="center">
<img align="center" src="./imgs/redundancy_removal.png", width=400><br>
å›¾4 è¯æ®è¯†åˆ«åŠåŸºäºè¯æ®é¢„æµ‹çš„ä¸¤é˜¶æ®µç­–ç•¥åœ¨é˜…è¯»ç†è§£ä»»åŠ¡ä¸Šçš„æ•ˆæœ
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [è¯æ®è¯†åˆ«åŠåŸºäºè¯æ®çš„é¢„æµ‹ç¤ºä¾‹-ä¸­æ–‡é˜…è¯»ç†è§£ä»»åŠ¡](https://aistudio.baidu.com/aistudio/projectdetail/4525331)

**å…³äºå¯ä¿¡å¢å¼ºæ›´å¤šå†…å®¹è¯·é˜…è¯»[tutorials](./tutorials)ã€‚**


## å®‰è£…

### ä¾èµ–
* `python`: >=3.6.2
* [`paddlepaddle`](https://www.paddlepaddle.org.cn/): >=2.0

### pip å®‰è£…

```shell
# ä¾èµ–paddlepaddleï¼Œæ¨èå®‰è£…CUDAç‰ˆæœ¬
pip install -U paddlepaddle-gpu
pip install -U trustai
```

### æºç ç¼–è¯‘
```shell
git clone git@github.com:PaddlePaddle/TrustAI.git
cd TrustAI
python setup.py install
```


## å¿«é€Ÿå¼€å§‹

### ç‰¹å¾çº§è¯æ®åˆ†æ
<details><summary>&emsp;ä»¥Integrated Gradientæ–¹æ³•ä¸ºä¾‹ï¼Œå…¶è°ƒç”¨æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š</summary>

```python
from trustai.demo import DEMO
from trustai.interpretation import IntGradInterpreter
from trustai.interpretation import visualize

demo = DEMO('chnsenticorp')
# init demo model
model = demo.get_model()
tokens, model_inputs = demo("è¿™ä¸ªå®¾é¦†æ¯”è¾ƒé™ˆæ—§äº†")
# tokens: List[List[str]], [['[CLS]', 'è¿™', 'ä¸ª', 'å®¾', 'é¦†', 'æ¯”', 'è¾ƒ', 'é™ˆ', 'æ—§', 'äº†', '[SEP]']]
# model_inputs: List[Paddle.Tensor]ï¼Œæ»¡è¶³`logits = model(*model_inputs)`
# init interpreter
interpreter = IntGradInterpreter(model)
result = interpreter(model_inputs)
# result: List[IGResult], result[0].attribtionsä¸tokens[0]ä¸€ä¸€å¯¹åº”ï¼Œè¡¨ç¤ºæ¯ä¸€ä¸ªtokenå¯¹é¢„æµ‹ç»“æœçš„æ”¯æŒç¨‹åº¦ï¼Œå³è¯æ®çš„æ”¯æŒåº¦åˆ†æ•°ã€‚
# result[0].attributions: [ 0.04054353,  0.12724458, -0.00042592,  0.01736268,  0.07130871, -0.00350687,
#                           0.01605285,  0.04392833,  0.04841821, -0.00514487,  0.13098583]

# å¯è§†åŒ–ç»“æœ
html = visualize(result, words=tokens)
# TrustAIæä¾›å¯è§†åŒ–è¾“å‡ºï¼Œå³æ ¹æ®è¾“å…¥ç‰¹å¾çš„æ”¯æŒåº¦ï¼Œä»¥ä¸åŒé¢œè‰²æ·±åº¦å±•ç¤ºç»“æœã€‚é¢œè‰²è¶Šæ·±è¡¨ç¤ºæ”¯æŒåº¦è¶Šå¤§ï¼Œè¶Šæµ…è¡¨ç¤ºæ”¯æŒåº¦è¶Šå°ã€‚
```

&emsp;æ›´å¤šè¯¦æƒ… - [ç‰¹å¾çº§è¯æ®åˆ†ææ–‡æ¡£](./trustai/interpretation/token_level/README.md)


</details>


### å®ä¾‹çº§è¯æ®åˆ†æ

<details><summary>&emsp;ä»¥Feature Similarityæ–¹æ³•ä¸ºä¾‹ï¼Œå…¶è°ƒç”¨æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š</summary>

```python
from trustai.demo import DEMO
from trustai.interpretation import FeatureSimilarityModel
demo = DEMO('chnsenticorp')
# init demo model
model = demo.get_model()
tokens, model_inputs = demo("æˆ¿é—´è®¾å¤‡æ¯”è¾ƒé™ˆæ—§ï¼Œæ²¡äº”æ˜Ÿæ ‡å‡† å®¢äººéå¸¸ä¸æ»¡æ„")
# tokens: List[List[str]]
# model_inputs: List[Paddle.Tensor]ï¼Œæ»¡è¶³`logits = model(*model_inputs)`
# get dataloader of train data, æ»¡è¶³`logits = model(*next(train_data_loader))`
train_data, train_dataloader = demo.get_train_data_and_dataloader()
# init interpreter
interpreter = FeatureSimilarityModel(model, train_dataloader, classifier_layer_name='classifier')
result = interpreter(model_inputs)
# result: List[ExampleResult], [ExampleResult(pred_label=0, pos_indexes=(7112, 1757, 4487), neg_indexes=(8952, 5986, 1715), pos_scores=(0.9454082250595093, 0.9445762038230896, 0.9439479112625122), neg_scores=(-0.2316494882106781, -0.23641490936279297, -0.23641490936279297))]
# ExampleResult.pos_indexes: List[int], æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®åœ¨è®­ç»ƒé›†ä¸­çš„ç´¢å¼•
# ExampleResult.neg_indexes: List[int], ä¸æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®åœ¨è®­ç»ƒé›†ä¸­çš„ç´¢å¼•
# ExampleResult.pos_scores: List[float], æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®çš„æ”¯æŒåº¦
# ExampleResult.neg_scores: List[float], ä¸æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®çš„æ”¯æŒåº¦
```

&emsp;æ›´å¤šè¯¦æƒ… - [å®ä¾‹çº§è¯æ®åˆ†ææ–‡æ¡£](./trustai/interpretation/example_level/README.md)

</details>

å…³äºæ¥å£ä½¿ç”¨çš„æ›´å¤šæ ·ä¾‹è§[examplesç›®å½•](./examples)


## <p id="åº”ç”¨æ¡ˆä¾‹">ğŸš€åº”ç”¨æ¡ˆä¾‹</p>

</details>

<details><summary> &emsp;è‡ªåŠ¨è¯†åˆ«è„æ•°æ®ï¼Œé™ä½äººåŠ›æ£€æŸ¥æˆæœ¬ </summary>
</br>

&emsp;&emsp;&emsp;[è®­ç»ƒæ•°æ®ä¸­è„æ•°æ®è‡ªåŠ¨è¯†åˆ«ç¤ºä¾‹](./tutorials/dirty_data_identification)

</details>

<details><summary> &emsp;ä»¥ä¸€åŠæ ‡æ³¨æˆæœ¬ï¼Œå¸¦æ¥æ›´å¤§æ•ˆæœæå‡ </summary>
</br>

&emsp;&emsp;&emsp;[è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³è¯†åˆ«åŠæœ‰æ•ˆæ•°æ®å¢å¼ºç¤ºä¾‹](./tutorials/sparse_data_identification)

</details>

<details><summary> &emsp;ç¼“è§£æ•°æ®é›†åç½®ï¼Œæå‡æ¨¡å‹é²æ£’æ€§ </summary>

&emsp;&emsp;&emsp;[æ•°æ®é›†åˆ†å¸ƒåç½®ç¼“è§£ - æ•°æ®æƒé‡ä¿®æ­£ç­–ç•¥ç¤ºä¾‹](./tutorials/data_bias_identification/less_learn_shortcut)

&emsp;&emsp;&emsp;[æ•°æ®é›†åˆ†å¸ƒåç½®ç¼“è§£ - æ•°æ®åˆ†å¸ƒä¿®æ­£ç­–ç•¥ç¤ºä¾‹](./tutorials/data_bias_identification/data_distribution_correction)

</details>

<details><summary> &emsp;è¯æ®è¯†åˆ«åŠåŸºäºè¯æ®çš„é¢„æµ‹ï¼Œæå‡æ¨¡å‹é²æ£’æ€§ </summary>

&emsp;&emsp;&emsp;[è¯æ®è¯†åˆ«åŠåŸºäºè¯æ®çš„é¢„æµ‹ç¤ºä¾‹](./tutorials/redundancy_removal)

</details>

</br>

å…³äºåº”ç”¨æ¡ˆä¾‹çš„æ›´å¤šè¯´æ˜ï¼Œè¯·å‚è€ƒ[tutorialsç›®å½•](./tutorials/)

## è¯„æµ‹æ¦œå•

è¯„æµ‹æ•°æ®é›†ä¸‹è½½ï¼š[åƒè¨€æ•°æ®é›†-å¯è§£é‡Šæ€§è¯„æµ‹](https://www.luge.ai/#/luge/task/taskDetail?taskId=15)

<details><summary> &emsp;é™æ—¶èµ›</summary>

* [2022 CCF BDCI åŸºäºæ–‡å¿ƒNLPå¤§æ¨¡å‹çš„é˜…è¯»ç†è§£å¯è§£é‡Šè¯„æµ‹](https://aistudio.baidu.com/aistudio/competition/detail/394/0/introduction)ï¼Œæ¯”èµ›æ—¶é—´ï¼š2022/08/29 - 2022/12/31
* [å…´æ™ºæ¯-æ·±åº¦å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§èµ›äº‹](http://www.aiinnovation.com.cn/#/trackDetail?id=23)ï¼Œå·²ç»“æŸ
* [2022 CCF BDCI åŸºäºæ–‡å¿ƒNLPå¤§æ¨¡å‹çš„é˜…è¯»ç†è§£å¯è§£é‡Šè¯„æµ‹](https://aistudio.baidu.com/aistudio/competition/detail/394/0/introduction)ï¼Œå·²ç»“æŸã€‚


</details>

<details><summary> &emsp;å¸¸è§„èµ›</summary>

* [åƒè¨€æ•°æ®é›†ï¼šæƒ…æ„Ÿåˆ†æå¯è§£é‡Šæ€§è¯„æµ‹ï¼ˆä¸­æ–‡ï¼‰](https://aistudio.baidu.com/aistudio/competition/detail/443/0/introduction)
* [åƒè¨€æ•°æ®é›†ï¼šæƒ…æ„Ÿåˆ†æå¯è§£é‡Šæ€§è¯„æµ‹ï¼ˆè‹±æ–‡ï¼‰](https://aistudio.baidu.com/aistudio/competition/detail/449/0/introduction)
* [åƒè¨€æ•°æ®é›†ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦å¯è§£é‡Šæ€§è¯„æµ‹ï¼ˆä¸­æ–‡ï¼‰](https://aistudio.baidu.com/aistudio/competition/detail/445/0/introduction)
* [åƒè¨€æ•°æ®é›†ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦å¯è§£é‡Šæ€§è¯„æµ‹ï¼ˆè‹±æ–‡ï¼‰](https://aistudio.baidu.com/aistudio/competition/detail/451/0/introduction)
* [åƒè¨€æ•°æ®é›†ï¼šé˜…è¯»ç†è§£å¯è§£é‡Šæ€§è¯„æµ‹ï¼ˆä¸­æ–‡ï¼‰](https://aistudio.baidu.com/aistudio/competition/detail/447/0/introduction)
* [åƒè¨€æ•°æ®é›†ï¼šé˜…è¯»ç†è§£å¯è§£é‡Šæ€§è¯„æµ‹ï¼ˆè‹±æ–‡ï¼‰](https://aistudio.baidu.com/aistudio/competition/detail/453/0/introduction)

</details>


## å­¦æœ¯æ–‡çŒ®
<details><summary>&emsp;è¯„æµ‹å‚è€ƒè®ºæ–‡ï¼ˆæ•°æ®é›†å’Œè¯„æµ‹æŒ‡æ ‡ï¼‰</summary>

* `Dataset` : [A Fine-grained Interpretability Evaluation Benchmark for Neural NLP, Wang Lijie, et al. 2022](https://arxiv.org/pdf/2205.11097.pdf)
* `Dataset` : [A Fine-grained Interpretability Evaluation Benchmark for Pre-trained Language Models, Shen yaozong, et al. 2022](https://arxiv.org/pdf/2207.13948.pdf)
* `Dataset` : [Benchmarking and Survey of Explanation Methods for Black Box Models](https://arxiv.org/pdf/2102.13076.pdf)
* `Dataset` : [ERASER: A Benchmark to Evaluate Rationalized NLP Models](https://aclanthology.org/2020.acl-main.408.pdf)
* `Metrics` : [On the Sensitivity and Stability of Model Interpretations in NLP](https://arxiv.org/abs/2104.08782)
* `Metrics` : [Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?](https://aclanthology.org/2020.acl-main.386.pdf)

</details>

<details><summary> &emsp;å¯ä¿¡åˆ†æå‚è€ƒè®ºæ–‡ </summary>

* `IntegratedGraients`: [Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017](https://arxiv.org/abs/1703.01365)
* `GradientShap`: [A Unified Approach to Interpreting Model Predictions, Scott M. Lundberg et al. 2017](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions)
* `Lime`: ["Why Should I Trust You?": Explaining the Predictions of Any Classifier, Marco Tulio Ribeiro et al. 2016](https://arxiv.org/abs/1602.04938)
* `NormLime`: [NormLime: A New Feature Importance Metric for Explaining Deep Neural Networks, Isaac Ahern et al. 2019](https://arxiv.org/abs/1909.04200)
* `Attention`: [Attention is not explanation, S Jain et al. 2019](https://arxiv.org/pdf/1902.10186.pdf)
* `Representer Pointer`:[Representer point selection for explaining deep neural networks, Chih-Kuan Yeh et al. 2018](https://proceedings.neurips.cc/paper/2018/file/8a7129b8f3edd95b7d969dfc2c8e9d9d-Paper.pdf)
* `Similarity based Instance Attribution`: [An Empirical Comparison of Instance Attribution Methods for NLP](https://arxiv.org/pdf/2104.04128.pdf)
* `Similarity based Instance Attribution`: [Input Similarity from the Neural Network Perspective](https://arxiv.org/pdf/2102.05262.pdf)

</details>

<details><summary> &emsp;å¯ä¿¡å¢å¼ºå‚è€ƒè®ºæ–‡ </summary>

  * `Bias` : [Towards Debiasing NLU Models from Unknown Biases](https://arxiv.org/pdf/2009.12303v4.pdf)
  * `Bias` : [Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU Models](https://arxiv.org/pdf/2103.06922.pdf)
  * `Bias` : [Learning to Learn to be Right for the Right Reasons](https://aclanthology.org/2021.naacl-main.304/)
  * `Robustness` : [Can Rationalization Improve Robustness](https://arxiv.org/pdf/2204.11790v1.pdf)

</details>

<details><summary> &emsp; ç«¯åˆ°ç«¯å¯è§£é‡Šæ€§æ¨¡å‹å‚è€ƒè®ºæ–‡ </summary>

* `Self-explaining` : [Self-explaining deep models with logic rule reasoning](https://arxiv.org/abs/2210.07024)
  
</details>

<details><summary> &emsp;è¿›é˜¶å­¦ä¹ ææ–™ </summary>

* `tutorials` : [ACL 2020 tutorial: Interpretability and Analysis in Neural NLP](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/slides/cs224n-2020-lecture20-interpretability.pdf) | [Video](https://www.youtube.com/watch?v=RkYASrVFdlU)
* `tutorials` : [EMNLP 2020 Tutorial on Interpreting Predictions of NLP Models](https://github.com/Eric-Wallace/interpretability-tutorial-emnlp2020) | [Video](https://www.youtube.com/watch?v=gprIzglUW1s)
* `tutorials` : [NAACL 2021 tutorialï¼šFine-grained Interpretation and Causation Analysis in Deep NLP Models](https://aclanthology.org/2021.naacl-tutorials.2.pdf) | [Video](https://www.youtube.com/watch?v=gprIzglUW1s)
* `Survey` : [Teach Me to Explain: A Review of Datasets for Explainable Natural Language Processing](https://openreview.net/pdf?id=ogNcxJn32BZ)
* `Survey` : [A Survey on the Explainability of Supervised Machine Learning](https://dl.acm.org/doi/pdf/10.1613/jair.1.12228)
* `Workshop` : [ICML 2022 Workshop: Interpretable Machine Learning in Healthcare](https://sites.google.com/view/imlh2022?pli=1)

</details>

<details><summary> &emsp;å„èµ›äº‹ä¼˜ç§€æ–¹æ¡ˆåˆ†äº« </summary>

  * `æƒ…æ„Ÿå¯è§£é‡Š` : [æƒ…æ„Ÿå¯è§£é‡Šå‰ä¸‰æ–¹æ¡ˆåˆ†äº«](https://aistudio.baidu.com/aistudio/competition/detail/443/0/datasets)ï¼ˆéœ€æŠ¥åï¼‰

</details>


## å¼•ç”¨
è¦å¼•ç”¨ TrustAI è¿›è¡Œç ”ç©¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿›è¡Œå¼•ç”¨ã€‚
```
@article{wang2022fine,
  title={A Fine-grained Interpretability Evaluation Benchmark for Neural NLP},
  author={Wang, Lijie and Shen, Yaozong and Peng, Shuyuan and Zhang, Shuai and Xiao, Xinyan and Liu, Hao and Tang, Hongxuan and Chen, Ying and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2205.11097},
  year={2022}
}
```

## è‡´è°¢
æˆ‘ä»¬å®ç°çš„å¯ä¿¡åˆ†ææ–¹æ³•å‚è€ƒå’Œä¾èµ–äº†[InterpretDL](https://github.com/PaddlePaddle/InterpretDL)é¡¹ç›®ï¼Œåœ¨æ­¤å‘InterpretDLçš„ä½œè€…è¡¨ç¤ºæ„Ÿè°¢ã€‚

## LICENSE
TrustAIéµå¾ª[Apache-2.0å¼€æºåè®®](./LICENSE)ã€‚
