
<p align="center">
  <img src="./imgs/trustai.png" align="middle"  width="500" />
</p>


<p align="center">
<a href="https://pypi.org/project/trustai/"><img src="https://img.shields.io/pypi/v/trustai.svg?&color=green"></a>
<a href="./LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
<a href=""><img src="https://img.shields.io/badge/python-3.6.2+-orange.svg"></a>
<a href=""><img src="https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-red.svg"></a>
</p>

<h4 align="center">
  <a href=#å®‰è£…> å®‰è£… </a> |
  <a href=#å¿«é€Ÿå¼€å§‹> å¿«é€Ÿå¼€å§‹ </a>|
  <a href=#å¯ä¿¡åˆ†æ> å¯ä¿¡åˆ†æåŠŸèƒ½ </a> |
  <a href=#å¯ä¿¡å¢å¼º> å¯ä¿¡å¢å¼ºåŠŸèƒ½ </a> |
  <a href=#ä½¿ç”¨ç¤ºä¾‹> ä½¿ç”¨ç¤ºä¾‹ </a>
</h4>

**TrustAI**æ˜¯ç™¾åº¦åŸºäºäº§ä¸šçº§æ·±åº¦å­¦ä¹ å¹³å°ã€é£æ¡¨ã€([PaddlePaddle](https://github.com/PaddlePaddle/Paddle))å¼€å‘çš„é›†å¯ä¿¡åˆ†æå’Œå¢å¼ºäºä¸€ä½“çš„å¯ä¿¡AIå·¥å…·é›†ï¼ŒåŠ©åŠ›å¼€å‘è€…æå‡æ¨¡å‹æ•ˆæœå’Œå¯ä¿¡åº¦ï¼Œæ¨åŠ¨æ¨¡å‹å®‰å…¨ã€å¯é çš„è½åœ°äºåº”ç”¨ã€‚


## News ğŸ“¢
* ğŸ”¥ 2022.8.20 TrustAIå‘å¸ƒå¯ä¿¡å¢å¼ºèƒ½åŠ›åŠåº”ç”¨æ¡ˆä¾‹
* ğŸ‰ 2022.5.20 **TrustAI**é¦–æ¬¡[å‘å¸ƒ](https://mp.weixin.qq.com/s/AqYReKRnki9TwI5huY1f5Q)ï¼

## ğŸ‘å¯ä¿¡åˆ†æåŠŸèƒ½
TrustAIæä¾›ç‰¹å¾çº§è¯æ®å’Œå®ä¾‹çº§è¯æ®åˆ†ææ–¹æ³•ï¼Œå…¨æ–¹ä½è§£é‡Šæ¨¡å‹çš„é¢„æµ‹ï¼Œå¸®åŠ©å¼€å‘è€…äº†è§£æ¨¡å‹é¢„æµ‹æœºåˆ¶ï¼Œä»¥åŠååŠ©ä½¿ç”¨è€…åŸºäºè¯æ®åšå‡ºæ­£ç¡®å†³ç­–ã€‚

### ç‰¹å¾çº§è¯æ®åˆ†æ

æ ¹æ®æ¨¡å‹é¢„æµ‹ç»“æœï¼Œä»è¾“å…¥æ–‡æœ¬ä¸­æå–æ¨¡å‹é¢„æµ‹æ‰€ä¾èµ–çš„è¯æ®ï¼Œå³è¾“å…¥æ–‡æœ¬ä¸­æ”¯æŒæ¨¡å‹é¢„æµ‹çš„é‡è¦è¯ã€‚

<p align="center">
  <img src="./imgs/token.png" align="middle", width="500" />
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [ åŸºäºTrustAIçš„ä¸­æ–‡æƒ…æ„Ÿç‰¹å¾çº§å¯ä¿¡åˆ†æç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4431334)

å…³äºæ–¹æ³•æ›´å¤šè¯¦ç»†å†…å®¹å¯å‚è€ƒ - [ç‰¹å¾çº§è¯æ®åˆ†ææ–‡æ¡£](./trustai/interpretation/token_level/README.md)

### å®ä¾‹çº§è¯æ®åˆ†æ


ä»è®­ç»ƒæ•°æ®ä¸­æ‰¾å‡ºå¯¹å½“å‰é¢„æµ‹å½±å“è¾ƒå¤§çš„è‹¥å¹²å®ä¾‹æ•°æ®ä½œä¸ºé¢„æµ‹è¯æ®ã€‚
<p align="center">
  <img src="./imgs/example.png" align="middle", width="500" />
</p>



åº”ç”¨ç¤ºä¾‹è§AI Studio - [åŸºäºTrustAIçš„ä¸­æ–‡æƒ…æ„Ÿå®ä¾‹çº§å¯ä¿¡åˆ†æç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4433286)

å…³äºæ–¹æ³•æ›´å¤šè¯¦ç»†å†…å®¹å¯å‚è€ƒ - [å®ä¾‹çº§è¯æ®åˆ†ææ–‡æ¡£](./trustai/interpretation/example_level/README.md)

## ğŸ’¥å¯ä¿¡å¢å¼ºåŠŸèƒ½
é™¤äº†æä¾›å¯ä¿¡åˆ†æç»“æœä»¥å¤–ï¼ŒTrustAIè¿˜åŒ…å«å¤šé¡¹å¢å¼ºåŠŸèƒ½ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…è§£å†³è®­ç»ƒæ•°æ®ç¼ºé™·é—®é¢˜ï¼Œç”¨æœ€å°çš„æ ‡æ³¨æˆæœ¬è·å¾—æœ€å¤§å¹…åº¦çš„æ•ˆæœæå‡ã€‚

### è§£å†³è®­ç»ƒæ•°æ®å­˜åœ¨è„æ•°æ®çš„é—®é¢˜


TrustAIæä¾›äº†è„æ•°æ®ï¼ˆå³æ ‡æ³¨è´¨é‡å·®çš„æ•°æ®ï¼‰è‡ªåŠ¨è¯†åˆ«åŠŸèƒ½ï¼Œå¸®åŠ©é™ä½äººå·¥æ£€æŸ¥æ•°æ®çš„æˆæœ¬ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šï¼ŒTrustAIè‡ªåŠ¨è¯†åˆ«çš„è„æ•°æ®æ¯”ä¾‹è¿œé«˜äºéšæœºé€‰æ‹©ç­–ç•¥ã€‚

<p align="center">
<img align="center" src="./imgs/dirty_analysis.png", width=400><br>
å›¾1 ä¸åŒç­–ç•¥è¯†åˆ«å‡ºçš„è„æ•°æ®æ¯”ä¾‹
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [è§£å†³è®­ç»ƒæ•°æ®å­˜åœ¨è„æ•°æ®çš„é—®é¢˜](https://aistudio.baidu.com/aistudio/projectdetail/4434058)

### è§£å†³è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³çš„é—®é¢˜

è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³ä¼šå¯¼è‡´æ¨¡å‹åœ¨å¯¹åº”çš„æµ‹è¯•æ•°æ®ä¸Šè¡¨ç°ä¸å¥½ã€‚TrustAIå¯è¯†åˆ«å› è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³è€Œå¯¼è‡´çš„é¢„æµ‹æ•ˆæœå·®çš„æµ‹è¯•æ ·æœ¬ï¼ˆè¿™äº›æ ·æœ¬æ„æˆçš„é›†åˆç§°ä¸ºç›®æ ‡é›†ï¼‰ï¼Œå¹¶å¸®åŠ©å¼€å‘è€…ä»æœªæ ‡æ³¨æ•°æ®ä¸­é€‰æ‹©æœ‰æ•ˆæ•°æ®è¿›è¡Œæ ‡æ³¨ï¼Œæé«˜è®­ç»ƒæ•°æ®è¦†ç›–åº¦å’Œæ¨¡å‹æ•ˆæœã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šï¼ŒTrustAIé€‰æ‹©çš„æœ‰æ•ˆæ•°æ®å¯¹æ¨¡å‹åœ¨ç›®æ ‡æ•°æ®ä¸Šçš„æ•ˆæœæå‡è¿œé«˜äºéšæœºé€‰æ‹©ç­–ç•¥ã€‚

<p align="center">
<img align="center" src="./imgs/sparse_analysis.png", width=400><br>
å›¾2 ç›®æ ‡é›†æå‡çš„æ•ˆæœ
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [è§£å†³è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³çš„é—®é¢˜](https://aistudio.baidu.com/aistudio/projectdetail/4434403)


### è§£å†³è®­ç»ƒæ•°æ®åˆ†å¸ƒåç½®çš„é—®é¢˜
ç¥ç»ç½‘ç»œæ¨¡å‹ä¼šåˆ©ç”¨æ•°æ®é›†ä¸­çš„åç½®åšé¢„æµ‹ï¼Œè¿™ä¼šå¯¼è‡´æ¨¡å‹æ²¡æœ‰å­¦ä¼šç†è§£è¯­è¨€ï¼Œé²æ£’æ€§å·®ã€‚TrustAIæä¾›äº†åˆ†å¸ƒä¿®æ­£å’Œæƒé‡ä¿®æ­£ä¸¤ç§ç­–ç•¥ï¼Œåœ¨ä¸éœ€è¦äººå·¥ä»‹å…¥çš„æ¡ä»¶ä¸‹ï¼Œæœ‰æ•ˆç¼“è§£æ•°æ®åç½®å¯¹æ¨¡å‹è®­ç»ƒçš„å½±å“ã€‚

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€çš„é²æ£’æ€§æ•°æ®é›†ä¸Šï¼ŒTrustAIçš„æƒé‡ä¿®æ­£å’Œåˆ†å¸ƒä¿®æ­£ç­–ç•¥åˆ†åˆ«å–å¾—æ˜æ˜¾æå‡ã€‚

<p align="center">
<img align="center" src="./imgs/bias_correction.png", width=400><br>
å›¾3 åç½®ä¿®æ­£åæ¨¡å‹åœ¨é²æ£’æ€§æ•°æ®é›†ä¸Šçš„æ•ˆæœ
</p>

åº”ç”¨ç¤ºä¾‹è§AI Studio - [æ•°æ®æƒé‡ä¿®æ­£](https://aistudio.baidu.com/aistudio/projectdetail/4434616)å’Œ[æ•°æ®åˆ†å¸ƒä¿®æ­£](https://aistudio.baidu.com/aistudio/projectdetail/4434652)

**å…³äºå¯ä¿¡å¢å¼ºæ›´å¤šå†…å®¹è¯·é˜…è¯»[tutorials](./tutorials)ã€‚**


## å®‰è£…

### ä¾èµ–
* `python`: >=3.6.2
* [`paddlepaddle`](https://www.paddlepaddle.org.cn/): >=2.0

### pip å®‰è£…

```shell
# ä¾èµ–paddlepaddleï¼Œæ¨èå®‰è£…CUDAç‰ˆæœ¬
pip install -U paddlepaddle-gpu
pip install -U trustai
```

### æºç ç¼–è¯‘
```shell
git clone git@github.com:PaddlePaddle/TrustAI.git
cd TrustAI
python setup.py install
```


## å¿«é€Ÿå¼€å§‹

### ç‰¹å¾çº§è¯æ®åˆ†æ
<details><summary>&emsp;ä»¥Integrated Gradientæ–¹æ³•ä¸ºä¾‹ï¼Œå…¶è°ƒç”¨æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š</summary>

```python
from trustai.demo import DEMO
from trustai.interpretation import IntGradInterpreter
from trustai.interpretation import visualize

demo = DEMO('chnsenticorp')
# init demo model
model = demo.get_model()
tokens, model_inputs = demo("è¿™ä¸ªå®¾é¦†æ¯”è¾ƒé™ˆæ—§äº†")
# tokens: List[List[str]], [['[CLS]', 'è¿™', 'ä¸ª', 'å®¾', 'é¦†', 'æ¯”', 'è¾ƒ', 'é™ˆ', 'æ—§', 'äº†', '[SEP]']]
# model_inputs: List[Paddle.Tensor]ï¼Œæ»¡è¶³`logits = model(*model_inputs)`
# init interpreter
interpreter = IntGradInterpreter(model)
result = interpreter(model_inputs)
# result: List[IGResult], result[0].attribtionsä¸tokens[0]ä¸€ä¸€å¯¹åº”ï¼Œè¡¨ç¤ºæ¯ä¸€ä¸ªtokenå¯¹é¢„æµ‹ç»“æœçš„æ”¯æŒç¨‹åº¦ï¼Œå³è¯æ®çš„æ”¯æŒåº¦åˆ†æ•°ã€‚
# result[0].attributions: [ 0.04054353,  0.12724458, -0.00042592,  0.01736268,  0.07130871, -0.00350687,
#                           0.01605285,  0.04392833,  0.04841821, -0.00514487,  0.13098583]

# å¯è§†åŒ–ç»“æœ
html = visualize(result, words=tokens)
# TrustAIæä¾›å¯è§†åŒ–è¾“å‡ºï¼Œå³æ ¹æ®è¾“å…¥ç‰¹å¾çš„æ”¯æŒåº¦ï¼Œä»¥ä¸åŒé¢œè‰²æ·±åº¦å±•ç¤ºç»“æœã€‚é¢œè‰²è¶Šæ·±è¡¨ç¤ºæ”¯æŒåº¦è¶Šå¤§ï¼Œè¶Šæµ…è¡¨ç¤ºæ”¯æŒåº¦è¶Šå°ã€‚
```
</details>


### å®ä¾‹çº§è¯æ®åˆ†æ

<details><summary>&emsp;ä»¥Feature Similarityæ–¹æ³•ä¸ºä¾‹ï¼Œå…¶è°ƒç”¨æ–¹æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š</summary>

```python
from trustai.demo import DEMO
from trustai.interpretation import FeatureSimilarityModel
demo = DEMO('chnsenticorp')
# init demo model
model = demo.get_model()
tokens, model_inputs = demo("æˆ¿é—´è®¾å¤‡æ¯”è¾ƒé™ˆæ—§ï¼Œæ²¡äº”æ˜Ÿæ ‡å‡† å®¢äººéå¸¸ä¸æ»¡æ„")
# tokens: List[List[str]]
# model_inputs: List[Paddle.Tensor]ï¼Œæ»¡è¶³`logits = model(*model_inputs)`
# get dataloader of train data, æ»¡è¶³`logits = model(*next(train_data_loader))`
train_data, train_dataloader = demo.get_train_data_and_dataloader()
# init interpreter
interpreter = FeatureSimilarityModel(model, train_dataloader, classifier_layer_name='classifier')
result = interpreter(model_inputs)
# result: List[ExampleResult], [ExampleResult(pred_label=0, pos_indexes=(7112, 1757, 4487), neg_indexes=(8952, 5986, 1715), pos_scores=(0.9454082250595093, 0.9445762038230896, 0.9439479112625122), neg_scores=(-0.2316494882106781, -0.23641490936279297, -0.23641490936279297))]
# ExampleResult.pos_indexes: List[int], æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®åœ¨è®­ç»ƒé›†ä¸­çš„ç´¢å¼•
# ExampleResult.neg_indexes: List[int], ä¸æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®åœ¨è®­ç»ƒé›†ä¸­çš„ç´¢å¼•
# ExampleResult.pos_scores: List[float], æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®çš„æ”¯æŒåº¦
# ExampleResult.neg_scores: List[float], ä¸æ”¯æŒå½“å‰é¢„æµ‹çš„è®­ç»ƒæ•°æ®çš„æ”¯æŒåº¦
```
</details>

## ğŸš€ä½¿ç”¨ç¤ºä¾‹

<details><summary> &emsp;ç‰¹å¾çº§è¯æ®åˆ†æç¤ºä¾‹ </summary>
</br>

[åŸºäºTrustAIçš„ä¸­æ–‡æƒ…æ„Ÿç‰¹å¾çº§è¯æ®åˆ†æç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4431334)

</details>
<details><summary> &emsp;å®ä¾‹çº§è¯æ®åˆ†æç¤ºä¾‹ </summary>
</br>

[åŸºäºTrustAIçš„ä¸­æ–‡æƒ…æ„Ÿå®ä¾‹çº§è¯æ®åˆ†æç¤ºä¾‹](https://aistudio.baidu.com/aistudio/projectdetail/4433286)

</details>
<details><summary> &emsp;è‡ªåŠ¨è¯†åˆ«è„æ•°æ®ï¼Œé™ä½äººåŠ›æ£€æŸ¥æˆæœ¬ </summary>
</br>

[è§£å†³è®­ç»ƒæ•°æ®å­˜åœ¨è„æ•°æ®çš„é—®é¢˜](https://aistudio.baidu.com/aistudio/projectdetail/4434058)

</details>
<details><summary> &emsp;æ ‡æ³¨å°½é‡å°‘çš„æ•°æ®ï¼Œæå‡æ¨¡å‹æ•ˆæœ </summary>
</br>

[è§£å†³è®­ç»ƒæ•°æ®è¦†ç›–ä¸è¶³çš„é—®é¢˜](https://aistudio.baidu.com/aistudio/projectdetail/4434403)

</details>
<details><summary> &emsp;ç¼“è§£æ•°æ®åç½®å¯¹æ¨¡å‹è®­ç»ƒçš„å½±å“ï¼Œæå‡æ¨¡å‹é²æ£’æ€§ </summary>
</br>

[æ•°æ®æƒé‡ä¿®æ­£](https://aistudio.baidu.com/aistudio/projectdetail/4434616)

[æ•°æ®åˆ†å¸ƒä¿®æ­£](https://aistudio.baidu.com/aistudio/projectdetail/4434652)

</details>



## ç›¸å…³æ–‡çŒ®

<details><summary> &emsp;å‚è€ƒè®ºæ–‡ </summary>

* `IntegratedGraients`: [Axiomatic Attribution for Deep Networks, Mukund Sundararajan et al. 2017](https://arxiv.org/abs/1703.01365)
* `GradientShap`: [A Unified Approach to Interpreting Model Predictions, Scott M. Lundberg et al. 2017](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions)
* `Lime`: ["Why Should I Trust You?": Explaining the Predictions of Any Classifier, Marco Tulio Ribeiro et al. 2016](https://arxiv.org/abs/1602.04938)
* `NormLime`: [NormLime: A New Feature Importance Metric for Explaining Deep Neural Networks, Isaac Ahern et al. 2019](https://arxiv.org/abs/1909.04200)
* `Attention`: [Attention is not explanation, S Jain et al. 2019](https://arxiv.org/pdf/1902.10186.pdf)
* `Representer Pointer`:[Representer point selection for explaining deep neural networks, Chih-Kuan Yeh et al. 2018](https://proceedings.neurips.cc/paper/2018/file/8a7129b8f3edd95b7d969dfc2c8e9d9d-Paper.pdf)
* `Evaluation`: [A Fine-grained Interpretability Evaluation Benchmark for Neural NLP, Wang Lijie, et al. 2022](https://arxiv.org/pdf/2205.11097.pdf)

</details>

<details><summary> &emsp;å­¦ä¹ ææ–™ </summary>

* `tutorials` : [ACL 2020 tutorial: Interpretability and Analysis in Neural NLP](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1204/slides/cs224n-2020-lecture20-interpretability.pdf) | [Video](https://www.youtube.com/watch?v=RkYASrVFdlU)
* `tutorials` : [EMNLP 2020 Tutorial on Interpreting Predictions of NLP Models](https://github.com/Eric-Wallace/interpretability-tutorial-emnlp2020) | [Video](https://www.youtube.com/watch?v=gprIzglUW1s)
* `tutorials` : [NAACL 2021 tutorialï¼šFine-grained Interpretation and Causation Analysis in Deep NLP Models](https://aclanthology.org/2021.naacl-tutorials.2.pdf) | [Video](https://www.youtube.com/watch?v=gprIzglUW1s)
* `Survey` : [Teach Me to Explain: A Review of Datasets for Explainable Natural Language Processing](https://openreview.net/pdf?id=ogNcxJn32BZ)
* `Survey` : [Benchmarking and Survey of Explanation Methods for Black Box Models](https://arxiv.org/pdf/2102.13076.pdf)
* `Survey` : [A Survey on the Explainability of Supervised Machine Learning](https://dl.acm.org/doi/pdf/10.1613/jair.1.12228)
* `Bias` : [Towards Debiasing NLU Models from Unknown Biases](https://arxiv.org/pdf/2009.12303v4.pdf)
* `Bias` : [Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU Models](https://arxiv.org/pdf/2103.06922.pdf)
* `Bias` : [Learning to Learn to be Right for the Right Reasons](https://aclanthology.org/2021.naacl-main.304/)
* `Robustness` : [Can Rationalization Improve Robustness](https://arxiv.org/pdf/2204.11790v1.pdf)


</details>


## å¼•ç”¨
è¦å¼•ç”¨ TrustAI è¿›è¡Œç ”ç©¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿›è¡Œå¼•ç”¨ã€‚
```
@article{wang2022fine,
  title={A Fine-grained Interpretability Evaluation Benchmark for Neural NLP},
  author={Wang, Lijie and Shen, Yaozong and Peng, Shuyuan and Zhang, Shuai and Xiao, Xinyan and Liu, Hao and Tang, Hongxuan and Chen, Ying and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2205.11097},
  year={2022}
}

```

## è‡´è°¢
æˆ‘ä»¬å®ç°çš„å¯ä¿¡åˆ†ææ–¹æ³•å‚è€ƒå’Œä¾èµ–äº†[InterpretDL](https://github.com/PaddlePaddle/InterpretDL)é¡¹ç›®ï¼Œåœ¨æ­¤å‘InterpretDLçš„ä½œè€…è¡¨ç¤ºæ„Ÿè°¢ã€‚

## LICENSE
TrustAIéµå¾ª[Apache-2.0å¼€æºåè®®](./LICENSE)ã€‚
