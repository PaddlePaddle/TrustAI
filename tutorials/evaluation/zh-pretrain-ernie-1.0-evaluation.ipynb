{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate for pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../../\")\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForMaskedLM, ErnieTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-04-10 20:50:25,353] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "W0410 20:50:25.355801   565 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0410 20:50:25.361073   565 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-04-10 20:50:29,934] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"ernie-1.0\"\n",
    " \n",
    "model = ErnieForMaskedLM.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level import IntGradInterpreter\n",
    "import numpy as np\n",
    "from assets.utils import convert_example, load_data\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "\n",
    "def masked_one_hot(input_ids, mask_id):\n",
    "    res = []\n",
    "    for x in input_ids:\n",
    "        if x == mask_id:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return res\n",
    "    \n",
    "# preprocess data functions \n",
    "def preprocess_fn(data):\n",
    "    examples = []\n",
    "    data_trans = []\n",
    "\n",
    "    for key in data:\n",
    "        data_trans.append(data[key])\n",
    " \n",
    "    for text in data_trans:\n",
    "        input_ids, segment_ids = convert_example(text, tokenizer, max_seq_length=128, is_test=True)\n",
    "        masked = masked_one_hot(input_ids, tokenizer.convert_tokens_to_ids('[MASK]'))\n",
    "        examples.append((input_ids, segment_ids, masked))\n",
    " \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # masked_one_hot\n",
    "    ): fn(samples)\n",
    " \n",
    "    input_ids, segment_ids, masked = batchify_fn(examples)\n",
    "    return paddle.to_tensor(input_ids, stop_gradient=False), paddle.to_tensor(segment_ids, stop_gradient=False),  paddle.to_tensor(masked, stop_gradient=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-10 20:50:31--  https://trustai.bj.bcebos.com/data_samples/pretrain_predict\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "--2022-04-10 20:50:31--  https://trustai.bj.bcebos.com/data_samples/pretrain_golden\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "data:\n",
      " [{'id': 0, 'context': '迈向充满希望的[MASK]世纪――一九九八年新年讲话（附图片１张）', 'sent_token': ['迈', '向', '充', '满', '希', '望', '的', '[MASK]', '世', '纪', '―', '―', '一', '九', '九', '八', '年', '新', '年', '讲', '话', '（', '附', '图', '片', '１', '张', '）']}, {'id': 100, 'context': '走进充满希望的[MASK]世纪――一九九八年新年讲话（附图片１张）', 'sent_token': ['走', '进', '充', '满', '希', '望', '的', '[MASK]', '世', '纪', '―', '―', '一', '九', '九', '八', '年', '新', '年', '讲', '话', '（', '附', '图', '片', '１', '张', '）']}]\n",
      "goldens:\n",
      " [{'sent_id': 0, 'sent_text': '迈向充满希望的[MASK]世纪――一九九八年新年讲话（附图片１张）', 'sent_token': ['迈', '向', '充', '满', '希', '望', '的', '[MASK]', '世', '纪', '―', '―', '一', '九', '九', '八', '年', '新', '年', '讲', '话', '（', '附', '图', '片', '１', '张', '）'], 'sent_token_with_idx': [['迈', 0], ['向', 1], ['充', 2], ['满', 3], ['希', 4], ['望', 5], ['的', 6], ['[MASK]', 7], ['世', 8], ['纪', 9], ['―', 10], ['―', 11], ['一', 12], ['九', 13], ['九', 14], ['八', 15], ['年', 16], ['新', 17], ['年', 18], ['讲', 19], ['话', 20], ['（', 21], ['附', 22], ['图', 23], ['片', 24], ['１', 25], ['张', 26], ['）', 27]], 'answers': '新', 'rationale': '迈向世纪', 'rationale_tokens': [[['迈', '向', '世', '纪']]], 'rationale_ids': [[[0, 1, 8, 9]]], 'sample_type': 'ori', 'pos': '形容词', 'rel_ids': [100]}, {'sent_id': 100, 'sent_text': '走进充满希望的[MASK]世纪――一九九八年新年讲话（附图片１张）', 'sent_token': ['走', '进', '充', '满', '希', '望', '的', '[MASK]', '世', '纪', '―', '―', '一', '九', '九', '八', '年', '新', '年', '讲', '话', '（', '附', '图', '片', '１', '张', '）'], 'sent_token_with_idx': [['走', 0], ['进', 1], ['充', 2], ['满', 3], ['希', 4], ['望', 5], ['的', 6], ['[MASK]', 7], ['世', 8], ['纪', 9], ['―', 10], ['―', 11], ['一', 12], ['九', 13], ['九', 14], ['八', 15], ['年', 16], ['新', 17], ['年', 18], ['讲', 19], ['话', 20], ['（', 21], ['附', 22], ['图', 23], ['片', 24], ['１', 25], ['张', 26], ['）', 27]], 'answers': '新', 'rationale': '走进世纪', 'rationale_tokens': [[['走', '进', '世', '纪']]], 'rationale_ids': [[[0, 1, 8, 9]]], 'sample_type': 'disturb', 'pos': '形容词', 'adv_type': '敏感-重要词'}]\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/data_samples/pretrain_predict -P ../assets/\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/data_samples/pretrain_golden -P ../assets/\n",
    "\n",
    "# predict data for predict\n",
    "data = load_data(\"../assets/pretrain_predict\")\n",
    "print(\"data:\\n\", list(data.values())[:2])\n",
    "\n",
    "# golden data for evluate\n",
    "goldens = load_data(\"../assets/pretrain_golden\")\n",
    "print(\"goldens:\\n\", list(goldens.values())[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IG Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level.common import get_word_offset\n",
    "from trustai.interpretation.token_level.data_processor import VisualizationTextRecord, visualize_text\n",
    "\n",
    "contexts = []\n",
    "batch_words = []\n",
    "for example in data.values():\n",
    "    contexts.append(\"[CLS]\" + \" \" + example['context'] + \" \" + \"[SEP]\")\n",
    "    batch_words.append([\"[CLS]\"] + example['sent_token'] + [\"[SEP]\"])\n",
    "word_offset_maps = []\n",
    "subword_offset_maps = []\n",
    "for i in range(len(contexts)):\n",
    "    word_offset_maps.append(get_word_offset(contexts[i], batch_words[i]))\n",
    "    subword_offset_maps.append(tokenizer.get_offset_mapping(contexts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level.common import ig_predict_fn_on_paddlenlp_pretrain\n",
    "\n",
    "ig = IntGradInterpreter(model, device=\"gpu\", predict_fn=ig_predict_fn_on_paddlenlp_pretrain)\n",
    "result = ig(preprocess_fn(data), steps=100)\n",
    "align_res = ig.alignment(result, contexts, batch_words, word_offset_maps, subword_offset_maps, special_tokens=[\"[CLS]\", '[SEP]', '[MASK]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'pred_label': array([8566], dtype=int64), 'pred_proba': array([[1.2374003e-16, 9.4894001e-16, 1.3985180e-12, ..., 3.1619304e-11,\n",
      "        8.0197359e-12, 1.4950932e-06]], dtype=float32), 'rationale': [(1, 11, 13, 15, 17)], 'non_rationale': [(2, 3, 4, 5, 6, 7, 9, 10, 12, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28)], 'rationale_tokens': [('迈', '―', '一', '九', '年')], 'non_rationale_tokens': [('向', '充', '满', '希', '望', '的', '世', '纪', '―', '九', '八', '新', '年', '讲', '话', '（', '附', '图', '片', '１', '张', '）')]}\n"
     ]
    }
   ],
   "source": [
    "def prepare_eval_data(data, results, paddle_model):\n",
    "    res = {}\n",
    "    for data_id, inter_res in zip(data, results):\n",
    "        eval_data = {}\n",
    "        eval_data['id'] = data_id\n",
    "        eval_data['pred_label'] = inter_res.pred_label\n",
    "        eval_data['pred_proba'] = inter_res.pred_proba\n",
    "        eval_data['rationale'] = [inter_res.rationale]\n",
    "        eval_data['non_rationale'] = [inter_res.non_rationale]\n",
    "        eval_data['rationale_tokens'] = [inter_res.rationale_tokens]\n",
    "        eval_data['non_rationale_tokens'] = [inter_res.non_rationale_tokens]\n",
    "\n",
    "        rationale_context = \"\".join(inter_res.rationale_tokens)\n",
    "        non_rationale_context = \"\".join(inter_res.non_rationale_tokens)\n",
    "\n",
    "        res[data_id] = eval_data\n",
    "    return res\n",
    "\n",
    "\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "print(list(predicts.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate for interpretation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map score: 0.46866666666666673\n",
      "plausibility f1: 0.29399877899877896\n",
      "plausibility iou f1: 0.0\n"
     ]
    }
   ],
   "source": [
    "from trustai.evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "result = evaluator.cal_map(goldens, predicts)\n",
    "print(\"map score:\",result)\n",
    "\n",
    "result = evaluator.cal_f1(goldens, predicts)\n",
    "print(\"plausibility f1:\", result)\n",
    "\n",
    "result = evaluator.calc_iou_f1(goldens, predicts)\n",
    "print(\"plausibility iou f1:\",result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map score: 0.7146666666666667\n",
      "plausibility f1: 0.29318070818070824\n",
      "plausibility iou f1: 0.0\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.token_level.common import attention_predict_fn_on_paddlenlp_pretrain\n",
    "from trustai.interpretation.token_level import AttentionInterpreter\n",
    "\n",
    "att = AttentionInterpreter(model, device=\"gpu\", predict_fn=attention_predict_fn_on_paddlenlp_pretrain)\n",
    "  \n",
    "result = att(preprocess_fn(data))\n",
    "align_res = att.alignment(result, contexts, batch_words, word_offset_maps, subword_offset_maps, special_tokens=[\"[CLS]\", '[SEP]', '[MASK]'])\n",
    "\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "\n",
    "result = evaluator.cal_map(goldens, predicts)\n",
    "print(\"map score:\",result)\n",
    "\n",
    "result = evaluator.cal_f1(goldens, predicts)\n",
    "print(\"plausibility f1:\", result)\n",
    "\n",
    "result = evaluator.calc_iou_f1(goldens, predicts)\n",
    "print(\"plausibility iou f1:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zs_py39': conda)",
   "metadata": {
    "interpreter": {
     "hash": "acea1e9fb1ca687a228f6dc71ee62aa15fcb20ac41dec3d8a9e155f35234403c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
