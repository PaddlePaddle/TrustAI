{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate for sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../../trustai/\")\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-04-10 20:57:25,372] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "W0410 20:57:25.374974  6294 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0410 20:57:25.380517  6294 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-04-10 20:57:30,213] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"ernie-1.0\"\n",
    " \n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-10 20:57:30--  https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 399595520 (381M) [application/x-tar]\n",
      "Saving to: ‘chnsenticorp-ernie-1.0.tar’\n",
      "\n",
      "100%[======================================>] 399,595,520  120MB/s   in 3.2s   \n",
      "\n",
      "2022-04-10 20:57:33 (120 MB/s) - ‘chnsenticorp-ernie-1.0.tar’ saved [399595520/399595520]\n",
      "\n",
      "chnsenticorp-ernie-1.0/\n",
      "chnsenticorp-ernie-1.0/tokenizer_config.json\n",
      "chnsenticorp-ernie-1.0/vocab.txt\n",
      "chnsenticorp-ernie-1.0/model_state.pdparams\n",
      "chnsenticorp-ernie-1.0/model_config.json\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])\n",
    "\n",
    "# Load the trained model.\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
    "!tar -xvf ./chnsenticorp-ernie-1.0.tar -C ../assets/\n",
    "!rm ./chnsenticorp-ernie-1.0.tar\n",
    "\n",
    "state_dict = paddle.load(f'../assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpretation.token_level import IntGradInterpreter\n",
    "import numpy as np\n",
    "from assets.utils import convert_example, load_data\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "# preprocess data functions \n",
    "def preprocess_fn(data):\n",
    "    examples = []\n",
    "    data_trans = []\n",
    "\n",
    "    for key in data:\n",
    "        data_trans.append(data[key])\n",
    " \n",
    "    for text in data_trans:\n",
    "        input_ids, segment_ids = convert_example(text, tokenizer, max_seq_length=128, is_test=True)\n",
    "        examples.append((input_ids, segment_ids))\n",
    " \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
    "    ): fn(samples)\n",
    " \n",
    "    input_ids, segment_ids = batchify_fn(examples)\n",
    "    return paddle.to_tensor(input_ids, stop_gradient=False), paddle.to_tensor(segment_ids, stop_gradient=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download data for predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-10 20:57:36--  https://trustai.bj.bcebos.com/data_samples/senti_ch_predict\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "--2022-04-10 20:57:37--  https://trustai.bj.bcebos.com/data_samples/senti_ch_golden\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n",
      "data:\n",
      " [{'id': 1, 'context': '特别垃圾的摄影店，服务态度差', 'sent_token': ['特', '别', '垃', '圾', '的', '摄', '影', '店', '，', '服', '务', '态', '度', '差']}, {'id': 4, 'context': '加油员服务态度特别好！加油站的油价合理！我经常在这里加油', 'sent_token': ['加', '油', '员', '服', '务', '态', '度', '特', '别', '好', '！', '加', '油', '站', '的', '油', '价', '合', '理', '！', '我', '经', '常', '在', '这', '里', '加', '油']}]\n",
      "goldens:\n",
      " [{'sent_id': 1, 'sent_text': '特别垃圾的摄影店，服务态度差', 'sent_label': 0, 'sent_token': ['特', '别', '垃', '圾', '的', '摄', '影', '店', '，', '服', '务', '态', '度', '差'], 'sent_type': 'single', 'sent_token_with_idx': [['特', 0], ['别', 1], ['垃', 2], ['圾', 3], ['的', 4], ['摄', 5], ['影', 6], ['店', 7], ['，', 8], ['服', 9], ['务', 10], ['态', 11], ['度', 12], ['差', 13]], 'rationale_tokens': [[['垃', '圾', '店'], ['态', '度', '差']]], 'sample_type': 'ori', 'rel_ids': [2162], 'rationale_ids': [[['2', '3', '7'], ['11', '12', '13']]]}, {'sent_id': 4, 'sent_text': '加油员服务态度特别好！加油站的油价合理！我经常在这里加油', 'sent_label': 1, 'sent_token': ['加', '油', '员', '服', '务', '态', '度', '特', '别', '好', '！', '加', '油', '站', '的', '油', '价', '合', '理', '！', '我', '经', '常', '在', '这', '里', '加', '油'], 'sent_type': 'single', 'sent_token_with_idx': [['加', 0], ['油', 1], ['员', 2], ['服', 3], ['务', 4], ['态', 5], ['度', 6], ['特', 7], ['别', 8], ['好', 9], ['！', 10], ['加', 11], ['油', 12], ['站', 13], ['的', 14], ['油', 15], ['价', 16], ['合', 17], ['理', 18], ['！', 19], ['我', 20], ['经', 21], ['常', 22], ['在', 23], ['这', 24], ['里', 25], ['加', 26], ['油', 27]], 'rationale_tokens': [[['态', '度', '好'], ['油', '价', '合', '理']]], 'sample_type': 'ori', 'rel_ids': [2165], 'rationale_ids': [[['5', '6', '9'], ['15', '16', '17', '18']]]}]\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/data_samples/senti_ch_predict -P ../assets/\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/data_samples/senti_ch_golden -P ../assets/\n",
    "\n",
    "# predict data for predict\n",
    "data = load_data(\"../assets/senti_ch_predict\")\n",
    "print(\"data:\\n\", list(data.values())[:2])\n",
    "\n",
    "# golden data for evluate\n",
    "goldens = load_data(\"../assets/senti_ch_golden\")\n",
    "print(\"goldens:\\n\", list(goldens.values())[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpretation.token_level.common import get_word_offset\n",
    "from interpretation.token_level.data_processor import VisualizationTextRecord, visualize_text\n",
    "\n",
    "contexts = []\n",
    "batch_words = []\n",
    "for example in data.values():\n",
    "    contexts.append(\"[CLS]\" + \" \" + example['context'] + \" \" + \"[SEP]\")\n",
    "    batch_words.append([\"[CLS]\"] + example['sent_token'] + [\"[SEP]\"])\n",
    "word_offset_maps = []\n",
    "subword_offset_maps = []\n",
    "for i in range(len(contexts)):\n",
    "    word_offset_maps.append(get_word_offset(contexts[i], batch_words[i]))\n",
    "    subword_offset_maps.append(tokenizer.get_offset_mapping(contexts[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IG Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntGradInterpreter(model, device=\"gpu\")\n",
    "result = ig(preprocess_fn(data), steps=100)\n",
    "align_res = ig.alignment(result, contexts, batch_words, word_offset_maps, subword_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'pred_label': 0, 'pred_proba': array([0.99891305, 0.00108691], dtype=float32), 'rationale': [(5, 7, 9, 12, 14)], 'non_rationale': [(1, 2, 3, 4, 6, 8, 10, 11, 13)], 'rationale_tokens': [('的', '影', '，', '态', '差')], 'non_rationale_tokens': [('特', '别', '垃', '圾', '摄', '店', '服', '务', '度')], 'rationale_pred_proba': [0.7971044, 0.20289561], 'non_rationale_pred_proba': [0.9967321, 0.0032678451]}\n"
     ]
    }
   ],
   "source": [
    "from interpretation.token_level.common import general_predict_fn\n",
    "def prepare_eval_data(data, results, paddle_model):\n",
    "    res = {}\n",
    "    for data_id, inter_res in zip(data, results):\n",
    "        eval_data = {}\n",
    "        eval_data['id'] = data_id\n",
    "        eval_data['pred_label'] = inter_res.pred_label\n",
    "        eval_data['pred_proba'] = inter_res.pred_proba\n",
    "        eval_data['rationale'] = [inter_res.rationale]\n",
    "        eval_data['non_rationale'] = [inter_res.non_rationale]\n",
    "        eval_data['rationale_tokens'] = [inter_res.rationale_tokens]\n",
    "        eval_data['non_rationale_tokens'] = [inter_res.non_rationale_tokens]\n",
    "\n",
    "        rationale_context = \"\".join(inter_res.rationale_tokens)\n",
    "        non_rationale_context = \"\".join(inter_res.non_rationale_tokens)\n",
    "\n",
    "        input_data = {'rationale': {'text': rationale_context}, 'no_rationale': {'text': non_rationale_context}}\n",
    "        _, pred_probas = general_predict_fn(preprocess_fn(input_data), paddle_model)\n",
    "        eval_data['rationale_pred_proba'] = list(pred_probas[0])\n",
    "        eval_data['non_rationale_pred_proba'] = list(pred_probas[1])\n",
    "        res[data_id] = eval_data\n",
    "    return res\n",
    "\n",
    "\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "print(list(predicts.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate for interpretation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map score: 0.3093333333333333\n",
      "plausibility f1: 0.5211560661560661\n",
      "plausibility iou f1: 0.3\n",
      "sufficency score: 0.12631417512893678 conciseness score: 0.07311496138572693\n"
     ]
    }
   ],
   "source": [
    "from evaluation import Evaluator\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "result = evaluator.cal_map(goldens, predicts)\n",
    "print(\"map score:\",result)\n",
    "\n",
    "result = evaluator.cal_f1(goldens, predicts)\n",
    "print(\"plausibility f1:\", result)\n",
    "\n",
    "result = evaluator.calc_iou_f1(goldens, predicts)\n",
    "print(\"plausibility iou f1:\",result)\n",
    "\n",
    "result = evaluator.cal_suf_com(goldens, predicts)\n",
    "print(\"sufficency score:\", result[0], \"conciseness score:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map score: 0.41\n",
      "plausibility f1: 0.4260317460317461\n",
      "plausibility iou f1: 0.0\n",
      "sufficency score: 0.13706786632537843 conciseness score: 0.29508517384529115\n"
     ]
    }
   ],
   "source": [
    "from interpretation.token_level.common import attention_predict_fn_on_paddlenlp\n",
    "from interpretation.token_level import AttentionInterpreter\n",
    "\n",
    "att = AttentionInterpreter(model, device=\"gpu\", predict_fn=attention_predict_fn_on_paddlenlp)\n",
    "  \n",
    "result = att(preprocess_fn(data))\n",
    "align_res = att.alignment(result, contexts, batch_words, word_offset_maps, subword_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])\n",
    "\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "\n",
    "result = evaluator.cal_map(goldens, predicts)\n",
    "print(\"map score:\",result)\n",
    "\n",
    "result = evaluator.cal_f1(goldens, predicts)\n",
    "print(\"plausibility f1:\", result)\n",
    "\n",
    "result = evaluator.calc_iou_f1(goldens, predicts)\n",
    "print(\"plausibility iou f1:\", result)\n",
    "\n",
    "result = evaluator.cal_suf_com(goldens, predicts)\n",
    "print(\"sufficency score:\", result[0], \"conciseness score:\", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map score: 0.484\n",
      "plausibility f1: 0.3719191919191919\n",
      "plausibility iou f1: 0.1\n",
      "sufficency score: 0.024930185079574584 conciseness score: 0.16205161809921265\n"
     ]
    }
   ],
   "source": [
    "from interpretation.token_level import LIMEInterpreter\n",
    "lime = LIMEInterpreter(model, device=\"gpu\",\n",
    "    unk_id=tokenizer.convert_tokens_to_ids('[UNK]'),\n",
    "    pad_id=tokenizer.convert_tokens_to_ids('[PAD]'))\n",
    "\n",
    "result = lime(preprocess_fn(data), num_samples=1000)\n",
    "align_res = lime.alignment(result, contexts, batch_words, word_offset_maps,      subword_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])\n",
    "\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "\n",
    "result = evaluator.cal_map(goldens, predicts)\n",
    "print(\"map score:\",result)\n",
    "\n",
    "result = evaluator.cal_f1(goldens, predicts)\n",
    "print(\"plausibility f1:\", result)\n",
    "\n",
    "result = evaluator.calc_iou_f1(goldens, predicts)\n",
    "print(\"plausibility iou f1:\",result)\n",
    "\n",
    "result = evaluator.cal_suf_com(goldens, predicts)\n",
    "print(\"sufficency score:\", result[0], \"conciseness score:\", result[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zs_py39': conda)",
   "metadata": {
    "interpreter": {
     "hash": "acea1e9fb1ca687a228f6dc71ee62aa15fcb20ac41dec3d8a9e155f35234403c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
