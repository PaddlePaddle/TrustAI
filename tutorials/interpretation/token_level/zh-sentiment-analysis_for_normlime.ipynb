{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NormLIME\n",
    "\n",
    "NormLIME method aggregates local models into global and class-specific interpretations. It is effective at recognizing important features. In this notebook, we use NormLIME method discover the words that contribute the most to positive and negative sentiment predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../../trustai/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model parameters\n",
    "\n",
    "We provide pre-trained model parameters. if users want to understand the training process, they can refer to this [page](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples/text_classification/rnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-07 20:58:33--  https://trustai.bj.bcebos.com/chnsenticorp-bilstm.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13690880 (13M) [application/x-tar]\n",
      "Saving to: ‘chnsenticorp-bilstm.tar’\n",
      "\n",
      "100%[======================================>] 13,690,880  62.1MB/s   in 0.2s   \n",
      "\n",
      "2022-04-07 20:58:33 (62.1 MB/s) - ‘chnsenticorp-bilstm.tar’ saved [13690880/13690880]\n",
      "\n",
      "chnsenticorp-bilstm/\n",
      "chnsenticorp-bilstm/final.pdparams\n",
      "chnsenticorp-bilstm/bilstm_word_dict.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.data import Vocab\n",
    "from paddlenlp.data import JiebaTokenizer\n",
    "\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/chnsenticorp-bilstm.tar\n",
    "!tar -xvf chnsenticorp-bilstm.tar -C ../../assets\n",
    "!rm ./chnsenticorp-bilstm.tar\n",
    "PARAMS_PATH = \"../../assets/chnsenticorp-bilstm/final.pdparams\"\n",
    "VOCAB_PATH = \"../../assets/chnsenticorp-bilstm/bilstm_word_dict.txt\"\n",
    "\n",
    "# init config\n",
    "vocab = Vocab.from_json(VOCAB_PATH)\n",
    "tokenizer = JiebaTokenizer(vocab)\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "vocab_size = len(vocab)\n",
    "num_classes = len(label_map)\n",
    "pad_token_id = vocab.to_indices('[PAD]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0407 20:58:34.161798 24117 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0407 20:58:34.170097 24117 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import LSTMModel\n",
    "\n",
    "# init model\n",
    "model = LSTMModel(vocab_size, num_classes, direction='bidirect', padding_idx=pad_token_id)\n",
    "state_dict = paddle.load(PARAMS_PATH)\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a preprocessing function that takes in a raw string and outputs the model inputs that can be fed into paddle_model.\n",
    "\n",
    "In this case, the raw string is splitted and mapped to word ids. texts is a list of lists, where each list contains a sequence of padded word ids. seq_lens is a list that contains the sequence length of each unpadded word ids in texts.\n",
    "\n",
    "Since the input data is a single raw string. Both texts and seq_lens has length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def preprocess_fn(text, tokenizer):\n",
    "    ids = tokenizer.encode(text)\n",
    "    texts = paddle.to_tensor([ids])\n",
    "    seq_lens = paddle.to_tensor(len(ids))\n",
    "    return texts, seq_lens\n",
    "preprocess_fn = partial(preprocess_fn, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 1200 samples in the training set as our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds = load_dataset(DATASET_NAME, splits=[\"train\"])\n",
    "data = [d['text'] for d in list(train_ds)[:1200]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NormLIMEInterpreter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 96/1200 [00:05<01:19, 13.92it/s]'本书其实没说什么，也看不出价值在哪，作者倒是牛，把西医批评的一无是处，感觉就是根本不懂科学' has been computed before. Check it if this is NOT expected.\n",
      " 27%|██▋       | 324/1200 [00:22<01:05, 13.38it/s]'外观设计的好，做工精美，京东快递速度也很迅速，特别是2699-100的价格简直无可挑剔！' has been computed before. Check it if this is NOT expected.\n",
      " 28%|██▊       | 337/1200 [00:23<00:51, 16.67it/s]'散热口很烫,可以加热水杯,也许AMD的CPU就这个德性,重装XP系统很麻烦' has been computed before. Check it if this is NOT expected.\n",
      " 47%|████▋     | 567/1200 [00:41<00:49, 12.91it/s]'东西不错，外观设计的好，做工精美，质量可靠，京东的送货速度很快！ 京东的东西质量还是比较放心的，没有多大问题，包装也不错，发货速度赞一个，基本当天都可以发货。东西刚用上，很不错，比想象中要好。' has been computed before. Check it if this is NOT expected.\n",
      " 52%|█████▏    | 624/1200 [00:46<00:46, 12.26it/s]'明明缺货却不显示，没货了也不通知一声，收货时才知道没有这个！当当就喜欢骗人！' has been computed before. Check it if this is NOT expected.\n",
      " 55%|█████▌    | 662/1200 [00:50<00:32, 16.67it/s]'临街.非常的吵.酒店的负责清洁的都是顺手牵羊或者无德之辈.共住了三次好像.前二次一次是洗发水和一次洗澡巾忘拿了.打电话过去都是没看到.估计拿走了或者扔了. 因为对合肥不熟悉,并且的确没什么好酒店.住了第三次.真汗!发现酒店的浴巾什么估计外包洗了.我知道全国洗酒店桑拿浴巾这行业非常薄利.甚至不能用自来水.不幸的是估计这家酒' has been computed before. Check it if this is NOT expected.\n",
      " 61%|██████▏   | 735/1200 [00:57<00:38, 11.95it/s]'一下子买了2台，同事一台自己一台。。。总体感觉还不错。。电池耐用，屏幕好，键盘好用。' has been computed before. Check it if this is NOT expected.\n",
      " 63%|██████▎   | 757/1200 [00:59<00:38, 11.61it/s]'我很愤怒，这本书我4月23号收到邮件说上海寄出，今天了5月7号了，我还没见到书的影子，居然让我写评论……希望像在当当上买书的朋友慎重了' has been computed before. Check it if this is NOT expected.\n",
      " 69%|██████▉   | 832/1200 [01:05<00:20, 17.94it/s]'刚住过这里，感觉不好，房间味道太大，一股子霉味，房间各种设施都很陈旧，我所预订的大床间，却没有宽带，只能一个住在双人标间。因为去的时候较晚，所以有点饿，结果在房间找了半天，只找了一个空荡荡的摆设冰箱。这么老的酒店还不装修一下，估计不会有回头客。好的一点是环境不错，但在海南，像这种花园式的宾馆还是不少的，并不构成特色。如果有人到洋浦来，建议住在海景花园宾馆，四星级设计，在房间门口的走廊上就面向大海，整个是个花园式布局。如果要洗浴，可以打个三轮车去干充（音译），只有几公里的路程。价格也很公道，238元大床间。' has been computed before. Check it if this is NOT expected.\n",
      " 70%|██████▉   | 838/1200 [01:05<00:19, 18.70it/s]'这本书我是买来送给爸妈，听说很简单易学，所以给妈妈看，让他们了解一些基本的健身之道，这样我们在外面工作也会比较安心。妈妈正在学，听她说还不错。' has been computed before. Check it if this is NOT expected.\n",
      " 72%|███████▏  | 858/1200 [01:07<00:25, 13.32it/s]'光盘发现有裂痕，无法使用，已联系当当客服中心申请换货，应该是14号连同书一起寄回当当客户部的，但到现在还没消息，请当当确认尽快发货' has been computed before. Check it if this is NOT expected.\n",
      " 73%|███████▎  | 872/1200 [01:09<00:39,  8.36it/s]'价格比同配置其他牌子电脑贵些。 装XP比较困难，因为SATA盘芯片驱动比较怪。' has been computed before. Check it if this is NOT expected.\n",
      " 74%|███████▍  | 894/1200 [01:11<00:28, 10.91it/s]'看到网上的热评终于忍不住买来一看,什么东西吗,完全一副显摆样老实说历史确实应该可以写的好看但似乎不该是这个样子吧,反正我除了看见一些新鲜词汇完全没觉得好看好玩明明惊险曲折的战争场面被他描述的寡淡无味人物性格不是通过冲突体现出来的而是硬生生,死板板下定义得出来的总之,不好看,没水平,没意义' has been computed before. Check it if this is NOT expected.\n",
      " 82%|████████▏ | 978/1200 [01:19<00:17, 12.76it/s]'服务还可以，房间好，888888888888888888888888' has been computed before. Check it if this is NOT expected.\n",
      " 83%|████████▎ | 996/1200 [01:21<00:17, 11.35it/s]'房间干净，还有净水装置，还有浴袍。免费送的早餐也过的去。性价比不错。唯一不足就是前台结帐的时间比较长！' has been computed before. Check it if this is NOT expected.\n",
      " 86%|████████▋ | 1038/1200 [01:25<00:11, 14.46it/s]'这位姐姐对这本书几近痴迷。我不好这一口，没有耐心看它。纯粹表扬一下这次送书的效率和质量。起码书的品相不错，好过我前两次购书。希望以后能保持。' has been computed before. Check it if this is NOT expected.\n",
      " 91%|█████████▏| 1096/1200 [01:31<00:09, 10.50it/s]'语言空洞，情节太离谱，没有感觉到震撼，只觉得这个人太倒霉了，也没有什么可以发掘的内涵，觉得整本书写得精彩点的部分的可能就是序了' has been computed before. Check it if this is NOT expected.\n",
      "'海景花园是我所有住过的５星酒店中服务最好的一家，另外他们的粤式餐厅非常地道，并且价格合理，如果去青岛还会再选它。 Fantastic 5 star hotel, good location and environment, with best service and very nice staff, strongly recommend. The Cantonese restaurant is one of the best, worth to try!!! 补充点评 2008年7月29日 ： &#32431;&#20013;&#26041;&#31649;&#29702;&#65292;&#38750;&#24120;&#26834;&#65281;' has been computed before. Check it if this is NOT expected.\n",
      "100%|██████████| 1200/1200 [01:42<00:00, 11.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from interpretation.token_level import NormLIMEInterpreter\n",
    "\n",
    "normlime = NormLIMEInterpreter(model,\n",
    "                               preprocess_fn,\n",
    "                               unk_id=vocab.to_indices('[UNK]'),\n",
    "                               pad_id=vocab.to_indices('[PAD]'),\n",
    "                               batch_size=50)\n",
    "result = normlime(data,\n",
    "                  num_samples=500,\n",
    "                  temp_data_file='../../assets/all_lime_weights.npz',\n",
    "                  save_path=\"../../assets/normlime_weights.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id2word = vocab.idx_to_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print interpret result\n",
    "In the cells below, we print the words with top 20 largest weights for positive and negative sentiments. Only words that appear at least 5 times are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>改进</td>\n",
       "      <td>0.029098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>电子版</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>很值</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>定</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>流畅</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>小巧</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>一句</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>舒适</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>亮</td>\n",
       "      <td>0.007260</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>大方</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>周到</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>高</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>不错</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>水果</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>整体</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>外观</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>帮</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>待机</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>价位</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>导致</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    weight  frequency\n",
       "0    改进  0.029098          5\n",
       "1   电子版  0.022340          5\n",
       "2    很值  0.012091          8\n",
       "3     定  0.010631          5\n",
       "4    流畅  0.010191         11\n",
       "5    小巧  0.009392         10\n",
       "6    一句  0.008710          5\n",
       "7    舒适  0.007505          9\n",
       "8     亮  0.007260         21\n",
       "9    大方  0.006879          5\n",
       "10   周到  0.006723          8\n",
       "11    高  0.006164         35\n",
       "12   不错  0.006106        225\n",
       "13   水果  0.005912         15\n",
       "14   整体  0.005495         20\n",
       "15   外观  0.005381         44\n",
       "16    帮  0.005273         11\n",
       "17   待机  0.005236          5\n",
       "18   价位  0.004638         11\n",
       "19   导致  0.004533          6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive\n",
    "temp = {id2word[wid]: result.attributions[1][wid] for wid in result.attributions[1]}\n",
    "W = [(word, weight[0], weight[1]) for word, weight in temp.items() if weight[1] >= 5]\n",
    "pd.DataFrame(data=sorted(W, key=lambda x: -x[1])[:20], columns=['word', 'weight', 'frequency'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>于丹</td>\n",
       "      <td>0.065560</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>声卡</td>\n",
       "      <td>0.059569</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>没收</td>\n",
       "      <td>0.057041</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>没到</td>\n",
       "      <td>0.038130</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>要是</td>\n",
       "      <td>0.037119</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>不适</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>重</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>不爽</td>\n",
       "      <td>0.035794</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>失望</td>\n",
       "      <td>0.031051</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>不然</td>\n",
       "      <td>0.030569</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>闷</td>\n",
       "      <td>0.029270</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>太难</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>极差</td>\n",
       "      <td>0.028104</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>很差</td>\n",
       "      <td>0.026222</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>芯</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>较差</td>\n",
       "      <td>0.023902</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>最差</td>\n",
       "      <td>0.022884</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>快递</td>\n",
       "      <td>0.021926</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>简直</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>热</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    weight  frequency\n",
       "0    于丹  0.065560          7\n",
       "1    声卡  0.059569          6\n",
       "2    没收  0.057041          8\n",
       "3    没到  0.038130          5\n",
       "4    要是  0.037119          9\n",
       "5    不适  0.036320          6\n",
       "6     重  0.035883         10\n",
       "7    不爽  0.035794          5\n",
       "8    失望  0.031051         23\n",
       "9    不然  0.030569          7\n",
       "10    闷  0.029270          5\n",
       "11   太难  0.029120          6\n",
       "12   极差  0.028104          8\n",
       "13   很差  0.026222         16\n",
       "14    芯  0.025628          7\n",
       "15   较差  0.023902          5\n",
       "16   最差  0.022884          8\n",
       "17   快递  0.021926          6\n",
       "18   简直  0.020032         18\n",
       "19    热  0.019471         19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative\n",
    "temp = {id2word[wid]: result.attributions[0][wid] for wid in result.attributions[0]}\n",
    "W = [(word, weight[0], weight[1]) for word, weight in temp.items() if weight[1] >= 5]\n",
    "pd.DataFrame(data=sorted(W, key=lambda x: -x[1])[:20], columns=['word', 'weight', 'frequency'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('zs_py39': conda)",
   "metadata": {
    "interpreter": {
     "hash": "acea1e9fb1ca687a228f6dc71ee62aa15fcb20ac41dec3d8a9e155f35234403c"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
