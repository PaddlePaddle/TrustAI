{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pretrained Model and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[2022-05-17 16:32:27,097] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "W0517 16:32:27.100387 29316 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0517 16:32:27.105998 29316 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-05-17 16:32:32,056] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer\n",
    "\n",
    "MODEL_NAME = 'ernie-1.0'\n",
    "\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Model\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.utils import training_model\n",
    "\n",
    "training_model(model, tokenizer, train_ds, dev_ds, save_dir=f'../../assets/{DATASET_NAME}-{MODEL_NAME}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-05-17 16:32:32--  https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 399595520 (381M) [application/x-tar]\n",
      "Saving to: ‘chnsenticorp-ernie-1.0.tar’\n",
      "\n",
      "100%[======================================>] 399,595,520  121MB/s   in 3.2s   \n",
      "\n",
      "2022-05-17 16:32:35 (121 MB/s) - ‘chnsenticorp-ernie-1.0.tar’ saved [399595520/399595520]\n",
      "\n",
      "chnsenticorp-ernie-1.0/\n",
      "chnsenticorp-ernie-1.0/tokenizer_config.json\n",
      "chnsenticorp-ernie-1.0/vocab.txt\n",
      "chnsenticorp-ernie-1.0/model_state.pdparams\n",
      "chnsenticorp-ernie-1.0/model_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model.\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
    "!tar -xvf ./chnsenticorp-ernie-1.0.tar -C ../../assets/\n",
    "!rm ./chnsenticorp-ernie-1.0.tar\n",
    "\n",
    "state_dict = paddle.load(f'../../assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the prediciton results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data: {'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, test_data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(test_data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "from assets.utils import create_dataloader, convert_example\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_seq_length = 128\n",
    "\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        is_test=True,\n",
    "    )\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "): [data for data in fn(samples)]\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature similarity Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting feature for given dataloader, it will take some time...\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.example_level.method.feature_similarity import FeatureSimilarityModel\n",
    "\n",
    "# classifier_layer_name is the layer name of the last output layer\n",
    "feature_sim = FeatureSimilarityModel(model, train_data_loader, classifier_layer_name='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting feature for given dataloader, it will take some time...\ntest data\ntext: 本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差\tpredict label: 0\nmost similar examples\ntext: 我选分期付款，在上海扣的款，在上海开的发票，东西却从北京用快递发出，真是舍近求远，害的我等了一星期才收到货，真是脑残！\tgold label: 0\ntext: 看到评价那么高，就买了，但女儿不喜欢，我看了一下，也不喜欢，不知所云，汽车什么的，都是过时的，或生活中没有的。不明白，为什么有这么高的评价。\tgold label: 0\ntext: 看到评价那么高，就买了，但女儿不喜欢，我看了一下，也不喜欢，不知所云，汽车什么的，都是过时的，或生活中没有的。不明白，为什么有这么高的评价。\tgold label: 0\nmost dissimilar examples\ntext: 昨晚看着看着就睡着了，今天早晨醒来就立马抓起继续啃，正逢小说结尾部分，也正如作者的期望，我被吓了一跳。这是我读东野圭吾小说最意料不到的事实。爱有很多种，可是当它变成某种负担时，还算爱吗？爱有多种表现形式，当某种行为让对方感觉负罪时，这还能叫做爱吗？爱可以很长久，当这种永恒变成一种恶梦时，还能归于最初的爱吗？爱可以深入骨髓，无法割除，当它接受无法预知的变数时，还能始终如一吗？\tgold label: 1\ntext: 她们是一群神秘、美丽的女人，从上古的嫘祖，到末代的婉如，每一个都吸引了无数人。我们翻开历史，她们似乎是男人的陪衬，可是当你细细研读，你会发现她们是不可或缺的人物，是每一个朝代最美丽的花朵，也是每一位皇帝的明珠。她们有的与丈夫情投意合，助男人打下一片天下，有的共享荣华，帮皇帝创造盛世，有的颠沛流离，与失意的他同甘共苦，有的……，这一切不仅仅是故事，更是历史，神秘、华美的历史。\tgold label: 1\ntext: 受重建轻管思想的影响，造成水利工程管理研究十分薄弱，涉及工程管理，特别是河道管理类的书籍就更少了。郑教授长期从事河道管理工作，有十分丰富的管理经验和理论修养。该书系统阐述了河道的基本理论，国内外先进管理模式和发展方向，对我国河道管理、法规现状进行了梳理，提出问题和措施问题，并对涉河项目行政许可、河道具体管理提出具体方法和指导，理念新，实用性强，非常有价值！江苏水利 刘\tgold label: 1\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "sim_fn = \"cos\"\n",
    "sample_num = 3\n",
    "predict_labels, most_sim_examples = feature_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"most similar examples\")\n",
    "    for example in most_sim_examples[i][0]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print(\"most dissimilar examples\")\n",
    "    for example in most_sim_examples[i][1]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting feature for given dataloader, it will take some time...\ntest data\ntext: 本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差\tpredict label: 0\nmost similar examples\ntext: 虽至于另外的那些更是不值一提，选来选去三星的这款不错。然以前用的三星不好，但这次不错\tgold label: 0\ntext: 京东太会糊弄人了，我选定的圆通 ，竟然给发了免费的经济EMS害我多花了8块钱！\tgold label: 0\ntext: 什么全球最大的中文网上商城，我呸！乱发货不说，客服态度差、处理速度慢、不主动。想忽忧消费者呀？\tgold label: 0\n\nmost dissimilar examples\ntext: 现代许多年轻人喜欢读那些女人气的散文，对民俗作品不屑一顾，其实，民俗民情才是我们中国文化的根。花再娇艳也要有根的支撑啊。太湖实在是茶文化的故乡，就算日本的茶道也起源于中国。更何况茶圣陆羽的茶经也在太湖写成。太湖畔的惠泉山水，曾经让唐朝宰相李德裕，像杨贵妃千里传荔枝一样的让快马从无锡送去惠泉山水到长安，只为煮茶品茗。太湖茶俗，实在影响了中国数千年啊。这本书，你值得拥有。\tgold label: 1\ntext: 她们是一群神秘、美丽的女人，从上古的嫘祖，到末代的婉如，每一个都吸引了无数人。我们翻开历史，她们似乎是男人的陪衬，可是当你细细研读，你会发现她们是不可或缺的人物，是每一个朝代最美丽的花朵，也是每一位皇帝的明珠。她们有的与丈夫情投意合，助男人打下一片天下，有的共享荣华，帮皇帝创造盛世，有的颠沛流离，与失意的他同甘共苦，有的……，这一切不仅仅是故事，更是历史，神秘、华美的历史。\tgold label: 1\ntext: 受重建轻管思想的影响，造成水利工程管理研究十分薄弱，涉及工程管理，特别是河道管理类的书籍就更少了。郑教授长期从事河道管理工作，有十分丰富的管理经验和理论修养。该书系统阐述了河道的基本理论，国内外先进管理模式和发展方向，对我国河道管理、法规现状进行了梳理，提出问题和措施问题，并对涉河项目行政许可、河道具体管理提出具体方法和指导，理念新，实用性强，非常有价值！江苏水利 刘\tgold label: 1\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "sim_fn = \"dot\"\n",
    "sample_num = 3\n",
    "predict_labels, most_sim_examples = feature_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"most similar examples\")\n",
    "    for example in most_sim_examples[i][0]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()\n",
    "    print(\"most dissimilar examples\")\n",
    "    for example in most_sim_examples[i][1]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting feature for given dataloader, it will take some time...\n[([3256, 9517, 3629], [5842, 8737, 3627])]\ntest data\ntext: 本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差\tpredict label: 0\nmost similar examples\ntext: 我选分期付款，在上海扣的款，在上海开的发票，东西却从北京用快递发出，真是舍近求远，害的我等了一星期才收到货，真是脑残！\tgold label: 0\ntext: 看到评价那么高，就买了，但女儿不喜欢，我看了一下，也不喜欢，不知所云，汽车什么的，都是过时的，或生活中没有的。不明白，为什么有这么高的评价。\tgold label: 0\ntext: 看到评价那么高，就买了，但女儿不喜欢，我看了一下，也不喜欢，不知所云，汽车什么的，都是过时的，或生活中没有的。不明白，为什么有这么高的评价。\tgold label: 0\nmost dissimilar examples\ntext: 现代许多年轻人喜欢读那些女人气的散文，对民俗作品不屑一顾，其实，民俗民情才是我们中国文化的根。花再娇艳也要有根的支撑啊。太湖实在是茶文化的故乡，就算日本的茶道也起源于中国。更何况茶圣陆羽的茶经也在太湖写成。太湖畔的惠泉山水，曾经让唐朝宰相李德裕，像杨贵妃千里传荔枝一样的让快马从无锡送去惠泉山水到长安，只为煮茶品茗。太湖茶俗，实在影响了中国数千年啊。这本书，你值得拥有。\tgold label: 1\ntext: 她们是一群神秘、美丽的女人，从上古的嫘祖，到末代的婉如，每一个都吸引了无数人。我们翻开历史，她们似乎是男人的陪衬，可是当你细细研读，你会发现她们是不可或缺的人物，是每一个朝代最美丽的花朵，也是每一位皇帝的明珠。她们有的与丈夫情投意合，助男人打下一片天下，有的共享荣华，帮皇帝创造盛世，有的颠沛流离，与失意的他同甘共苦，有的……，这一切不仅仅是故事，更是历史，神秘、华美的历史。\tgold label: 1\ntext: 受重建轻管思想的影响，造成水利工程管理研究十分薄弱，涉及工程管理，特别是河道管理类的书籍就更少了。郑教授长期从事河道管理工作，有十分丰富的管理经验和理论修养。该书系统阐述了河道的基本理论，国内外先进管理模式和发展方向，对我国河道管理、法规现状进行了梳理，提出问题和措施问题，并对涉河项目行政许可、河道具体管理提出具体方法和指导，理念新，实用性强，非常有价值！江苏水利 刘\tgold label: 1\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "sim_fn = \"euc\"\n",
    "sample_num = 3\n",
    "predict_labels, most_sim_examples = feature_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "print(most_sim_examples)\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"most similar examples\")\n",
    "    for example in most_sim_examples[i][0]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print(\"most dissimilar examples\")\n",
    "    for  example in most_sim_examples[i][1]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}