{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pretrained Model and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "sys.path.insert(0, \"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-06-07 14:38:18,410] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-2.0-en/ernie_v2_eng_base.pdparams\u001b[0m\n",
      "W0607 14:38:18.414284 31982 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0607 14:38:18.420110 31982 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-06-07 14:38:23,873] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-2.0-en/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer\n",
    "\n",
    "MODEL_NAME = 'ernie-2.0-en'\n",
    "\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'qqp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(\"glue\", name='qqp', splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Model\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.utils import training_model\n",
    "\n",
    "training_model(model, tokenizer, train_ds, dev_ds, save_dir=f'../../assets/{DATASET_NAME}-{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-07 14:38:26--  https://trustai.bj.bcebos.com/qqp-ernie-2.0-en.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 438200320 (418M) [application/x-tar]\n",
      "Saving to: ‘qqp-ernie-2.0-en.tar’\n",
      "\n",
      "100%[======================================>] 438,200,320  124MB/s   in 3.7s   \n",
      "\n",
      "2022-06-07 14:38:29 (112 MB/s) - ‘qqp-ernie-2.0-en.tar’ saved [438200320/438200320]\n",
      "\n",
      "qqp-ernie-2.0-en/\n",
      "qqp-ernie-2.0-en/tokenizer_config.json\n",
      "qqp-ernie-2.0-en/vocab.txt\n",
      "qqp-ernie-2.0-en/model_state.pdparams\n",
      "qqp-ernie-2.0-en/model_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model.\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/qqp-ernie-2.0-en.tar\n",
    "!tar -xvf ./qqp-ernie-2.0-en.tar -C ../../assets/\n",
    "!rm ./qqp-ernie-2.0-en.tar\n",
    "\n",
    "state_dict = paddle.load(f'../../assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the prediciton results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {'sentence1': 'What are the best novels in 2016?', 'sentence2': 'What are some of the best novels everyone should read?', 'labels': 0} \t Lable: negative\n",
      "Data: {'sentence1': 'How can I get rid of stage fear?', 'sentence2': 'How do I get rid of my stage fear?', 'labels': 1} \t Lable: positive\n",
      "Data: {'sentence1': 'Is it illegal to use iTunes music in a video?', 'sentence2': 'Can anyone get the music used in this video?', 'labels': 0} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "data = [\n",
    "    {'sentence1': 'What are the best novels in 2016?', 'sentence2': 'What are some of the best novels everyone should read?', 'labels': 0},\n",
    "    {'sentence1': 'How can I get rid of stage fear?', 'sentence2': 'How do I get rid of my stage fear?', 'labels': 1},\n",
    "    {'sentence1': 'Is it illegal to use iTunes music in a video?', 'sentence2': 'Can anyone get the music used in this video?', 'labels': 0},\n",
    "]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "from assets.utils import create_dataloader, convert_example\n",
    "\n",
    "DATASET_NAME = 'qqp'\n",
    "\n",
    "batch_size = 32\n",
    "max_seq_length = 128\n",
    "learning_rate = 5e-5 \n",
    "epochs = 3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        is_test=True,\n",
    "    )\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "): [data for data in fn(samples)]\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rrepresenter Pointer Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature for given dataloader, it will take some time...\n",
      "Training representer point model, it will take several minutes...\n",
      "L1 difference between ground truth prediction and prediction by representer theorem decomposition\n",
      "[0.00103879]\n",
      "pearson correlation between ground truth  prediction and prediciton by representer theorem\n",
      "0.9999959119461196\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.example_level.method.representer_point import RepresenterPointModel\n",
    "\n",
    "# classifier_layer_name is the layer name of the last output layer\n",
    "representer_model = RepresenterPointModel(model, train_data_loader, classifier_layer_name='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting feature for given dataloader, it will take some time...\n",
      "test data\n",
      "text: What are the best novels in 2016?\tWhat are some of the best novels everyone should read?\tpredict label: 0\n",
      "examples with positive influence\n",
      "text: How do I sell domains?\tWhat's the best way to sell a domain?\tgold label: 0\tscore: 0.0002862816909328103\n",
      "text: How do I make chocolate brownies?\tWhat's the best chocolate brownie recipe?\tgold label: 0\tscore: 0.00023215859255287796\n",
      "text: How do I lose weight faster?\tWhat are the best ways to lose weight?\tgold label: 0\tscore: 0.00022417452419176698\n",
      "examples with negative influence\n",
      "text: What are some query languages?sepsepWhat is query language?\tgold label: 1\tscore: -0.00017490192840341479\n",
      "text: What should I do if girl is sending mixed signals?sepsepWhy do girls give mixed signals?\tgold label: 0\tscore: -0.0001809245441108942\n",
      "text: Can we time travel anyhow?sepsepWhy can't we time travel?\tgold label: 0\tscore: -0.00020212694653309882\n",
      "\n",
      "test data\n",
      "text: How can I get rid of stage fear?\tHow do I get rid of my stage fear?\tpredict label: 1\n",
      "examples with positive influence\n",
      "text: Is this correct to introduce 2000 rupee note suddenly in India with ban of 500 and 1000 rupees notes?\tWhat are the benefits of ban on 500 and 1000 rupees note?\tgold label: 0\tscore: 0.00020671037782449275\n",
      "text: How can I log into Facebook without putting in a password?\tHow can I delete an old Facebook account that I forgot it's password?\tgold label: 1\tscore: 0.00014297335292212665\n",
      "text: Why does 500 and 1000 Rs notes banned by GOI and new notes of 500 and 2000 are issued?\tWhat do you think of the decision by the Indian Government to replace 1000 notes with 2000 notes?\tgold label: 1\tscore: 0.00014073029160499573\n",
      "examples with negative influence\n",
      "text: Where can I learn UX/UI?sepsepWhat is the best way to learn UI/UX?\tgold label: 1\tscore: -0.00015053694369271398\n",
      "text: What is the wisest decision you have ever made in your life and what was its outcome?sepsepWhat has been the best decision you've made in your life?\tgold label: 0\tscore: -0.0001507933484390378\n",
      "text: How do I learn theories?sepsepWhat is the best way to learn theory?\tgold label: 0\tscore: -0.00017231766832992435\n",
      "\n",
      "test data\n",
      "text: Is it illegal to use iTunes music in a video?\tCan anyone get the music used in this video?\tpredict label: 0\n",
      "examples with positive influence\n",
      "text: How do I sell domains?\tWhat's the best way to sell a domain?\tgold label: 0\tscore: 0.0002472692576702684\n",
      "text: How do I make chocolate brownies?\tWhat's the best chocolate brownie recipe?\tgold label: 0\tscore: 0.00019813647668343037\n",
      "text: How do I lose weight faster?\tWhat are the best ways to lose weight?\tgold label: 0\tscore: 0.0001977018400793895\n",
      "examples with negative influence\n",
      "text: What are some query languages?sepsepWhat is query language?\tgold label: 1\tscore: -0.00015528450603596866\n",
      "text: What should I do if girl is sending mixed signals?sepsepWhy do girls give mixed signals?\tgold label: 0\tscore: -0.00015574706776533276\n",
      "text: Can we time travel anyhow?sepsepWhy can't we time travel?\tgold label: 0\tscore: -0.00016652466729283333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch, print_result\n",
    "\n",
    "test_data = [\n",
    "    {'sentence1': 'What are the best novels in 2016?', 'sentence2': 'What are some of the best novels everyone should read?', 'labels': 0},\n",
    "    {'sentence1': 'How can I get rid of stage fear?', 'sentence2': 'How do I get rid of my stage fear?', 'labels': 1},\n",
    "    {'sentence1': 'Is it illegal to use iTunes music in a video?', 'sentence2': 'Can anyone get the music used in this video?', 'labels': 0},\n",
    "]\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "res = representer_model.interpret(test_dataloader)\n",
    "\n",
    "print_result(test_data, train_ds, res, data_name='qqp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
