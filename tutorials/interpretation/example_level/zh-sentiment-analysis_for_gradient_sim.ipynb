{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pretrained Model and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[2022-05-17 16:55:14,795] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "W0517 16:55:14.798794 27221 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0517 16:55:14.804426 27221 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-05-17 16:55:20,053] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer\n",
    "\n",
    "MODEL_NAME = 'ernie-1.0'\n",
    "\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Model\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.utils import training_model\n",
    "\n",
    "training_model(model, tokenizer, train_ds, dev_ds, save_dir=f'../../assets/{DATASET_NAME}-{MODEL_NAME}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-05-17 16:55:20--  https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 399595520 (381M) [application/x-tar]\n",
      "Saving to: ‘chnsenticorp-ernie-1.0.tar’\n",
      "\n",
      "100%[======================================>] 399,595,520  107MB/s   in 3.9s   \n",
      "\n",
      "2022-05-17 16:55:24 (97.9 MB/s) - ‘chnsenticorp-ernie-1.0.tar’ saved [399595520/399595520]\n",
      "\n",
      "chnsenticorp-ernie-1.0/\n",
      "chnsenticorp-ernie-1.0/tokenizer_config.json\n",
      "chnsenticorp-ernie-1.0/vocab.txt\n",
      "chnsenticorp-ernie-1.0/model_state.pdparams\n",
      "chnsenticorp-ernie-1.0/model_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model.\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
    "!tar -xvf ./chnsenticorp-ernie-1.0.tar -C ../../assets/\n",
    "!rm ./chnsenticorp-ernie-1.0.tar\n",
    "\n",
    "state_dict = paddle.load(f'../../assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the prediciton results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data: {'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, test_data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(test_data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "from assets.utils import create_dataloader, convert_example\n",
    "\n",
    "\n",
    "batch_size = 1 # attention\n",
    "max_seq_length = 128\n",
    "\n",
    "trans_func = partial(convert_example,\n",
    "                     tokenizer=tokenizer,\n",
    "                     max_seq_length=max_seq_length)\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "    Stack(dtype=\"int64\")  # label\n",
    "): [data for data in fn(samples)]\n",
    "train_data_loader = create_dataloader(train_ds,\n",
    "                                      mode='train',\n",
    "                                      batch_size=batch_size,\n",
    "                                      batchify_fn=batchify_fn,\n",
    "                                      trans_fn=trans_func,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient similarity Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting gradient for given dataloader, it will take some time...\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.example_level.method.gradient_similarity import GradientSimilarityModel\n",
    "\n",
    "# classifier_layer_name is the layer name of the last output layer\n",
    "grad_sim = GradientSimilarityModel(model, train_data_loader, classifier_layer_name='classifier', cached_train_grad=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting gradient for given dataloader, it will take some time...\ntest data\ntext: 本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差\tpredict label: 0\nmost similar examples\ntext: 我选分期付款，在上海扣的款，在上海开的发票，东西却从北京用快递发出，真是舍近求远，害的我等了一星期才收到货，真是脑残！\tgold label: 0\ntext: 看到评价那么高，就买了，但女儿不喜欢，我看了一下，也不喜欢，不知所云，汽车什么的，都是过时的，或生活中没有的。不明白，为什么有这么高的评价。\tgold label: 0\ntext: 看到评价那么高，就买了，但女儿不喜欢，我看了一下，也不喜欢，不知所云，汽车什么的，都是过时的，或生活中没有的。不明白，为什么有这么高的评价。\tgold label: 0\nmost dissimilar examples\ntext: 单位用户千万别买，支付太不方便。 一定要支票到帐才发货，结果给了支票，居然两天不到财务那里，找了一天才找到支票在那里。 18号下的订单，28号才送到，而且还是支付的现金，支票依然没有到帐。不知道那个单位可以忍受这样的服务。\tgold label: 1\ntext: 这款机子，我没发现任何值得说好的地方！等待我不停的投诉吧！。。。（下面的评价不让多写字，写了很多发不了）\tgold label: 1\ntext: 已经评过了，可是还要求我来评价，这是什么玩意啊？当当的一些功能特别的差劲！难道我买基本就得评价几次么？希望有人处理下这个功能，一点都不人性和智能！！！\tgold label: 1\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch, predict\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"positive\"}\n",
    "test_predict_labels = predict(model, test_data, tokenizer, label_map)\n",
    "for i in range(len(test_data)):\n",
    "    test_data[i][\"label\"] = 0 if test_predict_labels[i] == \"negative\" else 1\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer, with_label=True)\n",
    "\n",
    "\n",
    "sim_fn = \"cos\"\n",
    "sample_num = 3\n",
    "predict_labels, most_sim_examples = grad_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"most similar examples\")\n",
    "    for example in most_sim_examples[i][0]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print(\"most dissimilar examples\")\n",
    "    for example in most_sim_examples[i][1]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting gradient for given dataloader, it will take some time...\ntest data\ntext: 本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差\tpredict label: 0\nmost similar examples\ntext: 交通还比较方便,价格相对便宜,但是设施有些陈旧,没有网络可上网,服务生的素质相对较低些,如果重新装修在这个位置应该还是不错.\tgold label: 0\ntext: 看评论说有卖到4299还送瑞星杀毒，就是不知道是何时，如果消息属实，那确实会有点郁闷！\tgold label: 0\ntext: 答应当初买电脑送包，可到消灾快一个月了，还没有送，准备退货了，不诚信，以后买东西必须东西全才可以付款\tgold label: 0\nmost dissimilar examples\ntext: 太一般了 网络慢的跟蜗牛一个等级 还高速呢 真晕 补充点评 2008年4月2日 ： 也没早餐 点评\tgold label: 1\ntext: 自己去松江配送点拿的货，一打看就看到显示屏下方的有一处黑漆掉色严重．是帮朋友买的，郁闷中．\tgold label: 1\ntext: 笔记本不错，京东不够厚道，钻石抢的和现在促销价没差几分，这不是忽悠我们钻石一族吗？？？\tgold label: 1\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"positive\"}\n",
    "test_predict_labels = predict(model, test_data, tokenizer, label_map)\n",
    "for i in range(len(test_data)):\n",
    "    test_data[i][\"label\"] = 0 if test_predict_labels[i] == \"negative\" else 1\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer, with_label=True)\n",
    "\n",
    "sim_fn = \"dot\"\n",
    "sample_num = 3\n",
    "predict_labels, most_sim_examples = grad_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"most similar examples\")\n",
    "    for example in most_sim_examples[i][0]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print(\"most dissimilar examples\")\n",
    "    for example in most_sim_examples[i][1]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}