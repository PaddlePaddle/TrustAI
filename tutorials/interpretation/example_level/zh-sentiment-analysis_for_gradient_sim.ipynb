{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pretrained Model and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[2022-05-20 11:30:29,532] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "W0520 11:30:29.535794 37076 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0520 11:30:29.541231 37076 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-05-20 11:30:35,084] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer\n",
    "\n",
    "MODEL_NAME = 'ernie-1.0'\n",
    "\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Model\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.utils import training_model\n",
    "\n",
    "training_model(model, tokenizer, train_ds, dev_ds, save_dir=f'../../assets/{DATASET_NAME}-{MODEL_NAME}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-05-20 11:30:35--  https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 399595520 (381M) [application/x-tar]\n",
      "Saving to: ‘chnsenticorp-ernie-1.0.tar’\n",
      "\n",
      "100%[======================================>] 399,595,520  119MB/s   in 3.2s   \n",
      "\n",
      "2022-05-20 11:30:38 (119 MB/s) - ‘chnsenticorp-ernie-1.0.tar’ saved [399595520/399595520]\n",
      "\n",
      "chnsenticorp-ernie-1.0/\n",
      "chnsenticorp-ernie-1.0/tokenizer_config.json\n",
      "chnsenticorp-ernie-1.0/vocab.txt\n",
      "chnsenticorp-ernie-1.0/model_state.pdparams\n",
      "chnsenticorp-ernie-1.0/model_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model.\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
    "!tar -xvf ./chnsenticorp-ernie-1.0.tar -C ../../assets/\n",
    "!rm ./chnsenticorp-ernie-1.0.tar\n",
    "\n",
    "state_dict = paddle.load(f'../../assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the prediciton results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data: {'text': '没有光驱,重装Windows需要外接光驱,对于电脑新手会很麻烦(没什么人会用Linux吧)'} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "test_data = [{'text': '没有光驱,重装Windows需要外接光驱,对于电脑新手会很麻烦(没什么人会用Linux吧)'}]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, test_data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(test_data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "from assets.utils import create_dataloader, convert_example\n",
    "\n",
    "\n",
    "batch_size = 1 # attention\n",
    "max_seq_length = 128\n",
    "\n",
    "trans_func = partial(convert_example,\n",
    "                     tokenizer=tokenizer,\n",
    "                     max_seq_length=max_seq_length,\n",
    "                     is_test=True)\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "): [data for data in fn(samples)]\n",
    "train_data_loader = create_dataloader(train_ds,\n",
    "                                      mode='train',\n",
    "                                      batch_size=batch_size,\n",
    "                                      batchify_fn=batchify_fn,\n",
    "                                      trans_fn=trans_func,\n",
    "                                      shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient similarity Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting gradient for given dataloader, it will take some time...\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.example_level.method.gradient_similarity import GradientSimilarityModel\n",
    "\n",
    "# classifier_layer_name is the layer name of the last output layer\n",
    "grad_sim = GradientSimilarityModel(model, train_data_loader, classifier_layer_name='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting gradient for given dataloader, it will take some time...\ntest data\ntext: 没有光驱,重装Windows需要外接光驱,对于电脑新手会很麻烦(没什么人会用Linux吧)\tpredict label: 0\nexamples with positive influence\ntext: Linux系统不太好用,平时习惯用Windows xp 系统,一下子用这个系统感觉很不习惯,建议开发或预装Windows xp系统.\tgold label: 0\ntext: 1、机器较沉 2、VISTA用起来不习惯，且占系统较多 3、音频插口、右前侧的二个USB口在用鼠标时感觉手靠得太近了\tgold label: 0\ntext: vista系统下也没有无线网卡驱动，用驱动精灵可解决。 机器稍有点重。 散热有待改进。\tgold label: 0\nexamples with negative influence\ntext: 价格确实比较高，而且还没有早餐提供。 携程拿到的价格不好？还是自己保留起来不愿意让利给我们这些客户呢？ 到前台搞价格，430就可以了。\tgold label: 1\ntext: 买机器送的移动硬盘2.5寸250G的，没开封，想卖出，感兴趣短息联系，北京13901019711\tgold label: 1\ntext: 买机器送的移动硬盘2.5寸250G的，没开封，想卖出，感兴趣短息联系，北京13901019711\tgold label: 0\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch, predict\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "sim_fn = \"cos\"\n",
    "sample_num = 3\n",
    "predict_labels, pos_examples, neg_examples = grad_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"examples with positive influence\")\n",
    "    for example in pos_examples[i]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print(\"examples with negative influence\")\n",
    "    for example in neg_examples[i]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting gradient for given dataloader, it will take some time...\ntest data\ntext: 没有光驱,重装Windows需要外接光驱,对于电脑新手会很麻烦(没什么人会用Linux吧)\tpredict label: 0\nexamples with positive influence\ntext: 看评论说有卖到4299还送瑞星杀毒，就是不知道是何时，如果消息属实，那确实会有点郁闷！\tgold label: 0\ntext: 自己去松江配送点拿的货，一打看就看到显示屏下方的有一处黑漆掉色严重．是帮朋友买的，郁闷中．\tgold label: 1\ntext: 建议酒店餐厅预备当地产的酒水,以备外地客人品尝.\tgold label: 0\nexamples with negative influence\ntext: 价格确实比较高，而且还没有早餐提供。 携程拿到的价格不好？还是自己保留起来不愿意让利给我们这些客户呢？ 到前台搞价格，430就可以了。\tgold label: 1\ntext: 买机器送的移动硬盘2.5寸250G的，没开封，想卖出，感兴趣短息联系，北京13901019711\tgold label: 1\ntext: 买机器送的移动硬盘2.5寸250G的，没开封，想卖出，感兴趣短息联系，北京13901019711\tgold label: 0\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "sim_fn = \"dot\"\n",
    "sample_num = 3\n",
    "predict_labels, pos_examples, neg_examples = grad_sim.interpret(\n",
    "        test_dataloader, sample_num=sample_num, sim_fn=sim_fn\n",
    "    )\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    print(\"test data\")\n",
    "    print(f\"text: {test_data[i]['text']}\\tpredict label: {predict_labels[i]}\")\n",
    "    print(\"examples with positive influence\")\n",
    "    for example in pos_examples[i]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print(\"examples with negative influence\")\n",
    "    for example in neg_examples[i]:\n",
    "        print(\n",
    "            f\"text: {train_ds.data[example]['text']}\\tgold label: {train_ds.data[example]['label']}\"\n",
    "        )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}