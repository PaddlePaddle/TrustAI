{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pretrained Model and the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "sys.path.insert(0, \"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[2022-06-27 00:31:37,791] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\u001b[0m\n",
      "W0627 00:31:37.793457 11209 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\n",
      "W0627 00:31:37.798871 11209 gpu_context.cc:306] device: 0, cuDNN Version: 8.2.\n",
      "\u001b[32m[2022-06-27 00:31:48,109] [    INFO]\u001b[0m - Already cached /home/zhangshuai/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer\n",
    "\n",
    "MODEL_NAME = 'ernie-1.0'\n",
    "\n",
    "model = ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO 2022-06-27 00:31:48,143 download.py:117] unique_endpoints {''}\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = 'chnsenticorp'\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Model\n",
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.utils import training_model\n",
    "\n",
    "training_model(model, tokenizer, train_ds, dev_ds, save_dir=f'../../assets/{DATASET_NAME}-{MODEL_NAME}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-06-27 00:31:48--  https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
      "Resolving trustai.bj.bcebos.com (trustai.bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to trustai.bj.bcebos.com (trustai.bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 399595520 (381M) [application/x-tar]\n",
      "Saving to: ‘chnsenticorp-ernie-1.0.tar’\n",
      "\n",
      "100%[======================================>] 399,595,520  120MB/s   in 3.2s   \n",
      "\n",
      "2022-06-27 00:31:51 (120 MB/s) - ‘chnsenticorp-ernie-1.0.tar’ saved [399595520/399595520]\n",
      "\n",
      "chnsenticorp-ernie-1.0/\n",
      "chnsenticorp-ernie-1.0/tokenizer_config.json\n",
      "chnsenticorp-ernie-1.0/vocab.txt\n",
      "chnsenticorp-ernie-1.0/model_state.pdparams\n",
      "chnsenticorp-ernie-1.0/model_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model.\n",
    "!wget --no-check-certificate -c https://trustai.bj.bcebos.com/chnsenticorp-ernie-1.0.tar\n",
    "!tar -xvf ./chnsenticorp-ernie-1.0.tar -C ../../assets/\n",
    "!rm ./chnsenticorp-ernie-1.0.tar\n",
    "\n",
    "state_dict = paddle.load(f'../../assets/{DATASET_NAME}-{MODEL_NAME}/model_state.pdparams')\n",
    "model.set_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the prediciton results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data: {'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'} \t Lable: negative\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import predict\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "label_map = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "results = predict(\n",
    "    model, test_data, tokenizer, label_map, batch_size=batch_size)\n",
    "\n",
    "for idx, text in enumerate(test_data):\n",
    "    print('Data: {} \\t Lable: {}'.format(text, results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "\n",
    "from assets.utils import create_dataloader, convert_example\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_seq_length = 128\n",
    "learning_rate = 5e-5 \n",
    "epochs = 3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "\n",
    "trans_func = partial(\n",
    "        convert_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "        is_test=True,\n",
    "    )\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "): [data for data in fn(samples)]\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rrepresenter Pointer Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting feature from given dataloader, it will take some time...\n",
      "INFO 2022-06-27 00:33:10,949 representer_point.py:131] Eopch:   0\tloss:[0.06501473]\tphi_loss:[0.04564954]\tgrad:[0.00098725]\n",
      "Training representer point model, it will take several minutes...\n",
      "INFO 2022-06-27 00:33:13,883 representer_point.py:131] Eopch:1000\tloss:[0.04877458]\tphi_loss:[0.04610152]\tgrad:[4.310665e-05]\n",
      "INFO 2022-06-27 00:33:15,629 representer_point.py:124] stopping criteria reached in epoch:1717\n",
      "L1 difference between ground truth prediction and prediction by representer theorem decomposition\n",
      "[0.00264857]\n",
      "pearson correlation between ground truth  prediction and prediciton by representer theorem\n",
      "0.9998619306573363\n"
     ]
    }
   ],
   "source": [
    "from trustai.interpretation.example_level.method.representer_point import RepresenterPointModel\n",
    "\n",
    "# classifier_layer_name is the layer name of the last output layer\n",
    "representer_model = RepresenterPointModel(model, train_data_loader, classifier_layer_name='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test data\ntext: 本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差\tpredict label: 0\nexamples with positive influence\ntext: 感觉非常奇怪,这套书我明明都写了两次评论了,可我的当当始终提醒我对这套书写评论!晕啊!这是套很好的书,也不用我写几次评论吧!\tgold label: 1\tscore: 0.03509486839175224\ntext: 1）背面少个螺丝钉,说是thinkpad都少，靠 2）键盘周围的壳不平整，按下去发现有：“滋啦滋啦”声音，我才意识到，那是个双面胶，按下去就不上来了，过会儿还是回弹上来，很明显仅靠双面胶是 粘不住的，你还不如拿502呢，起码这样粘得严实还能让我心里舒服（但是这样只是弥补质量问题），何必还弄个滋啦兹啦的声音，多闹心啊，（还有一地方用了双面胶，我换内存的时候发现键盘下部盖子左侧打不开，一直不敢用力\tgold label: 1\tscore: 0.03008781559765339\ntext: 用了6年的THINKPAD,一直认为是笔记本中最好的! 现在这台新的让我......哎!!\tgold label: 0\tscore: 0.029884016141295433\nexamples with negative influence\ntext: 是LINUX系统 相当及其恶心 不知道这狗 日 的是什么想法 要强行逼我们使用啊 买了两台电脑 一个事VISTA系统 一个 是 LINUX 就没见一个XP的 网上销售这东西 最重要的是打架尽量不要涉及到售后服务这块 尽量是都搞好了相安无事 其实网上的售后服务比没有售后服务还差劲 我的THINKPAD SL400就是因为换货期间以为是键盘小问题就懒得换了\tgold label: 1\tscore: -0.07112713158130646\ntext: 盼了2周终于拿到本了，一开机就屏不亮，本人自己跑回总部退机，现在还在等着检测，说要等上15个工作日，呵呵，买个电脑容易吗？时间浪费的起吗？请问？\tgold label: 0\tscore: -0.0723314955830574\ntext: 价格确实比较高，而且还没有早餐提供。 携程拿到的价格不好？还是自己保留起来不愿意让利给我们这些客户呢？ 到前台搞价格，430就可以了。\tgold label: 1\tscore: -0.0824359655380249\n\n"
     ]
    }
   ],
   "source": [
    "from assets.utils import create_dataloader_from_scratch, print_result\n",
    "\n",
    "test_data = [{'text': '本来不想评价了，但为了携程的携粉们，还是说一下，这称不上是九点，细说就真没必要了，就一个字：差'}]\n",
    "\n",
    "# process text to model input\n",
    "test_dataloader = create_dataloader_from_scratch(test_data, tokenizer)\n",
    "\n",
    "res = []\n",
    "for batch in test_dataloader:\n",
    "    res += representer_model.interpret(batch)\n",
    "\n",
    "print_result(test_data, train_ds, res, data_name='chnsenticorp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}