{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 『2022 CCF BDCI』- 阅读理解可解释性评测\n",
    "## 1、项目介绍\n",
    "深度学习模型在很多NLP任务上已经取得巨大成功，但其常被当作一个黑盒使用，内部预测机制对使用者是不透明的。这使得深度学习模型结果不被使用者信任，增加了落地难度，尤其在医疗、法律等特殊领域。同时，当模型出现效果不好或鲁棒性差等问题时，由于不了解其内部机制，很难对模型进行改进优化。近期，深度学习模型的可解释性被越来越多的人关注。但模型的可解释性评估还不够完善，本基线提供了阅读理解任务的评测数据和相关评测指标，旨在评估模型的可解释性。\n",
    "## 2、基线运行\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依赖安装\n",
    "安装一些必须的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -U paddlepaddle-gpu==2.2.2\n",
    "!pip3 install -U paddlenlp==2.3.0",
    "!pip3 install -U trustai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备\n",
    "#### 1）模型训练数据\n",
    "我们推荐使用DuReader-robust数据集训练中文相似度计算模型。Paddlenlp框架会自动下载及缓存训练数据集，默认缓存存储路径为\"~/.paddlenlp/datasets\"。如需修改训练数据，请参考『初始化工作』中DATASET_NAME的修改。\n",
    "#### 2）下载预训练模型\n",
    "基线使用了ERNIE-3.0-base预训练模型。Paddlenlp框架自动缓存模型文件，默认缓存存储路径为\"~/.paddlenlp/models\"。如需修改依赖的预训练模型，请在『初始化工作』中修改MODEL_NAME。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化工作\n",
    "初始化工作包括了模型选择及加载、训练数据集选择、模型存储路径设定、抽取证据的长度占原文本长度的比例设定等。可按需更改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import ErnieForQuestionAnswering, ErnieTokenizer\n",
    "from mrc_utils import *\n",
    "\n",
    "# Select pre-trained model\n",
    "MODEL_NAME = \"ernie-3.0-base-zh\" # choose from [\"ernie-1.0\", \"ernie-1.0-base-zh\", \"ernie-1.0-large-zh-cw\", \"ernie-2.0-base-zh\", \"ernie-2.0-large-zh\", \"ernie-3.0-xbase-zh\", \"ernie-3.0-base-zh\", \"ernie-3.0-medium-zh\", \"ernie-3.0-mini-zh\", \"ernie-3.0-micro-zh\", \"ernie-3.0-nano-zh\"]\n",
    "# Select dataset for model training\n",
    "DATASET_NAME = 'dureader_robust'\n",
    "# Set the path to save the trained model\n",
    "MODEL_SAVE_PATH = f'save_model/{DATASET_NAME}-{MODEL_NAME}'\n",
    "# Set the rationale length ratio which determines the length of the extracted rationales.\n",
    "RATIONALE_RATIO = 0.096 # 0.096 for Chinese dataset, 0.102 for English dataset\n",
    "\n",
    "# Init model and tokenizer\n",
    "model = ErnieForQuestionAnswering.from_pretrained(MODEL_NAME, num_classes=2)\n",
    "tokenizer = ErnieTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "这里以ERNIE-3.0为例训练一个阅读理解模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "# Hyperparameters\n",
    "batch_size = 12\n",
    "max_seq_length = 512\n",
    "epochs = 3  #3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "doc_stride = 512\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Load dataset\n",
    "train_ds, dev_ds, test_ds = load_dataset(DATASET_NAME, splits=[\"train\", \"dev\", \"test\"])\n",
    "\n",
    "# Start training\n",
    "training_mrc_model(model, \n",
    "                tokenizer,\n",
    "                train_ds, \n",
    "                dev_ds,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                learning_rate=learning_rate,\n",
    "                warmup_proportion=warmup_proportion,\n",
    "                max_seq_length=max_seq_length,\n",
    "                doc_stride=doc_stride, \n",
    "                weight_decay=weight_decay,\n",
    "                save_dir=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要度分数获取\n",
    "该步为输入中每个词赋一个重要度分数，表示该词对预测的影响度。重要度分数获取共分三步。\n",
    "#### 1）加载模型和评测数据集\n",
    "更改模型以及评估数据的存储路径（MODEL_PATH和DATA_PATH），完成模型和评测数据集的加载。赛段一数据量为1855条，赛段二数据量为4366条，请确认评测数据集完整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "from functools import partial\n",
    "\n",
    "# Correct MODEL_PATH and DATA_PATH before executing\n",
    "MODEL_PATH = MODEL_SAVE_PATH + '/model_state.pdparams'\n",
    "DATA_PATH = 'mrc_interpretation.txt'\n",
    "\n",
    "# Load the trained parameters\n",
    "state_dict = paddle.load(MODEL_PATH)\n",
    "model.set_dict(state_dict)\n",
    "\n",
    "# Load test data\n",
    "data_ds = DuReader().read(DATA_PATH)\n",
    "data = load_data(DATA_PATH)\n",
    "print(\"Num of data:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2）数据预处理\n",
    "\n",
    "a) 输入格式化：将输入的两个文本组织成模型预测所需格式，如对于Ernie3.0-base模型，其输入形式为[CLS]question[SEP]context[SEP]\n",
    "\n",
    "b) 分词位置索引：计算每个分词结果对应的原文位置索引，这里的分词包括模型分词和标准分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T10:23:21.698100Z",
     "iopub.status.busy": "2022-07-23T10:23:21.697467Z",
     "iopub.status.idle": "2022-07-23T10:23:33.024199Z",
     "shell.execute_reply": "2022-07-23T10:23:33.023048Z",
     "shell.execute_reply.started": "2022-07-23T10:23:21.698048Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mrc_utils import *\n",
    "# Hyperparameters\n",
    "batch_size = 12\n",
    "max_seq_length = 512\n",
    "epochs = 3  #3\n",
    "warmup_proportion = 0.1\n",
    "weight_decay = 0.01\n",
    "doc_stride = 512\n",
    "\n",
    "# Prepare dataloader\n",
    "test_trans_func = partial(prepare_validation_features, \n",
    "                            max_seq_length=max_seq_length, \n",
    "                            doc_stride=doc_stride,\n",
    "                            tokenizer=tokenizer)\n",
    "                            \n",
    "data_ds.map(test_trans_func, batched=True, num_workers=4)\n",
    "test_batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "        data_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_batchify_fn = lambda samples, fn=Dict({\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\n",
    "}): fn(samples)\n",
    "test_data_loader = paddle.io.DataLoader(\n",
    "    dataset=data_ds,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    collate_fn=test_batchify_fn,\n",
    "    return_list=True)\n",
    "\n",
    "# Get offset maps which will be used for score alignment\n",
    "contexts, standard_split, ori_offset_maps, standard_split_offset_maps = pre_process(data, data_ds, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）重要度分数获取\n",
    "我们提供attention和IG两种解释方法，可根据实际实验结果选取最有效的一种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a） Attention-based Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T09:28:49.773656Z",
     "iopub.status.busy": "2022-07-23T09:28:49.773034Z",
     "iopub.status.idle": "2022-07-23T09:29:17.231638Z",
     "shell.execute_reply": "2022-07-23T09:29:17.230237Z",
     "shell.execute_reply.started": "2022-07-23T09:28:49.773625Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level import AttentionInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "import paddle\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Init an attention interpreter and get the importance scores\n",
    "att = AttentionInterpreter(model, device=\"gpu\", predict_fn=attention_predict_fn)\n",
    "\n",
    "# Use attention interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in test_data_loader:\n",
    "    if interp_results:\n",
    "        interp_results += att(batch)\n",
    "    else:\n",
    "        interp_results = att(batch)\n",
    "\n",
    "# Trim the output to get scores only for context\n",
    "interp_results = trim_output(interp_results, data_ds, tokenizer)\n",
    "\n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = att.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b）IG-based Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T10:23:41.778007Z",
     "iopub.status.busy": "2022-07-23T10:23:41.777371Z",
     "iopub.status.idle": "2022-07-23T12:18:59.775221Z",
     "shell.execute_reply": "2022-07-23T12:18:59.774267Z",
     "shell.execute_reply.started": "2022-07-23T10:23:41.777963Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trustai.interpretation.token_level import IntGradInterpreter\n",
    "from utils import create_dataloader_from_scratch\n",
    "# Hyperparameters\n",
    "IG_STEP = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Init an IG interpreter\n",
    "ig = IntGradInterpreter(model, predict_fn=IG_predict_fn, device=\"gpu\")\n",
    "\n",
    "# Use IG interpreter to get the importance scores for all data\n",
    "interp_results = None\n",
    "for batch in test_data_loader:\n",
    "    if interp_results:\n",
    "        interp_results += ig(batch, steps=IG_STEP)\n",
    "    else:\n",
    "        interp_results = ig(batch, steps=IG_STEP)\n",
    "\n",
    "# trim the output to get scores only for context\n",
    "interp_results = trim_output(interp_results, data_ds, tokenizer)\n",
    "\n",
    "# Align the results back to the standard splited tokens so that it can be evaluated correctly later\n",
    "align_res = ig.alignment(interp_results, contexts, standard_split, standard_split_offset_maps, ori_offset_maps, special_tokens=[\"[CLS]\", '[SEP]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成用于评估的数据\n",
    "评估文件格式要求是3列数据：编号\\t预测答案\\t证据，我们提供了脚本将模型输出结果转成评估所需格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T12:25:45.320933Z",
     "iopub.status.busy": "2022-07-23T12:25:45.320292Z",
     "iopub.status.idle": "2022-07-23T12:25:45.711638Z",
     "shell.execute_reply": "2022-07-23T12:25:45.710752Z",
     "shell.execute_reply.started": "2022-07-23T12:25:45.320887Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Re-sort the token index according to their importance scores\n",
    "def resort(index_array, importance_score):\n",
    "    res = sorted([[idx, importance_score[idx]] for idx in index_array], key=lambda x:x[1], reverse=True)\n",
    "    res = [n[0] for n in res]\n",
    "    return res\n",
    "\n",
    "# Post-prepare the result data so that it can be used for the evaluation directly\n",
    "def prepare_eval_data(data, results, paddle_model):\n",
    "    res = {}\n",
    "    idx = 0\n",
    "    for data_id, inter_res in zip(data, results):\n",
    "        \n",
    "        # Split importance score vectors for query and title from inter_res.word_attributions\n",
    "        importance_score = np.array(inter_res.word_attributions[1:-1])\n",
    "        # Extract topK importance scores\n",
    "        topk = math.ceil(len(data[data_id]['sent_token'])*RATIONALE_RATIO)\n",
    "        \n",
    "        eval_data = {}        \n",
    "        eval_data['id'] = data_id\n",
    "        label = list(inter_res.pred_label)\n",
    "        if label[0]>=label[1]+1:\n",
    "            eval_data['pred_label'] = ''\n",
    "        else:\n",
    "            eval_data['pred_label'] = ''.join(tokenizer.convert_ids_to_tokens(data_ds[idx]['input_ids'][label[0]:label[1]+1]))\n",
    "        # Find the token index of the topK importance scores\n",
    "        eval_data['rationale'] = np.argpartition(importance_score, -topk)[-topk:]\n",
    "        # Re-sort the token index according to their importance scores\n",
    "        eval_data['rationale'] = resort(eval_data['rationale'], importance_score)\n",
    "\n",
    "        res[data_id] = eval_data\n",
    "        idx += 1\n",
    "    return res\n",
    "\n",
    "# Generate results for evaluation\n",
    "predicts = prepare_eval_data(data, align_res, model)\n",
    "out_file = open('./mrc_rationale.txt', 'w')\n",
    "for key in predicts:\n",
    "    out_file.write(str(predicts[key]['id'])+'\\t'+ str(predicts[key]['pred_label'])+'\\t')\n",
    "    for idx in predicts[key]['rationale'][:-1]:\n",
    "        out_file.write(str(idx)+',')\n",
    "    out_file.write(str(predicts[key]['rationale'][-1])+'\\n')\n",
    "out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
